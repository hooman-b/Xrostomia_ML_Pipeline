{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this notebook, I will describe all the steps that I have taken to make a new dataset for Weekly CTs.\n",
    "\n",
    "Basically, the process contains five different steps:\n",
    "\n",
    "1. Navigation of the folder in which one think there maybe any weeklyCTs. These folders can be on this computer or a user can just make these folders by downloading new patients from MIRADA or other UMCG datasets.\n",
    "\n",
    "2. Extracting only weeklyCTs from these folders and make an excel file from them.\n",
    "\n",
    "3. Transferring the new-founded weeklyCTs into a destination folder (it can be an existing folder for the weeklyCTs or a new folder).\n",
    "\n",
    "4. Making a report excel file of some information about the weeklyCTs in the destination file and some clinical information from the patients who have these weeklyCTs.\n",
    "\n",
    "5. Making a pannel that contains different information about the WeeklyCT dataset.\n",
    "\n",
    "6. A Watchdog is keep the track of all the additions to the destination folder, and save them in a log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from datetime import time, datetime, date\n",
    "\n",
    "# DICOM Libraries\n",
    "import pydicom as pdcm\n",
    "from pydicom.tag import Tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Navigation Phase\n",
    "### DICOM Files\n",
    "All kinds of CTs were stored in the form of DICOM files. DICOM, which stands for Digital Imaging and Communications in Medicine, is a standard for transmitting, storing, and sharing medical images. DICOM files contain information about medical images, such as X-rays, CT scans, MRIs, and ultrasound. This standard ensures the interoperability of medical imaging equipment from different manufacturers. Some key features are:\n",
    "\n",
    "**Metadata:** DICOM files store not only the pixel data of the medical images but also a wealth of metadata. This metadata includes patient information, imaging device details, acquisition parameters, and more.\n",
    "\n",
    "**Interoperability:** DICOM enables the exchange of medical images and related information between different devices and systems. This interoperability is crucial in healthcare settings where various imaging modalities and equipment are used.\n",
    "\n",
    "**Structured Data:** DICOM files use a structured format for information, allowing for consistency and ease of interpretation by different systems. This makes it possible for healthcare professionals to access and understand the data regardless of the equipment used to capture or generate the images.\n",
    "\n",
    "For information of different tags and the definitions one can use the following links: [Wiki](https://en.wikipedia.org/wiki/DICOM), [link](https://dicom.innolitics.com/ciods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_name(image, subf):\n",
    "\n",
    "    # find the name of the folder\n",
    "    try:\n",
    "        folder_name = image[Tag(0x0008103e)].value\n",
    "\n",
    "    except:\n",
    "        study = image[Tag(0x00081030)].value\n",
    "        patient_id = image[Tag(0x00100020)].value\n",
    "        print(f'Warning: folder {study} with {patient_id} ID does NOT have Series Description')\n",
    "        folder_name = subf.split('\\\\')[-1]  \n",
    "\n",
    "    return folder_name\n",
    "\n",
    "def get_patient_id(image):\n",
    "\n",
    "    # Extract the patient ID\n",
    "    try:\n",
    "        patient_id = int(image[Tag(0x00100020)].value)\n",
    "\n",
    "    except:\n",
    "        print(f'Warning: There is NO patient ID')\n",
    "        patient_id = None\n",
    "\n",
    "    return patient_id\n",
    "\n",
    "def get_probable_weklyct_name(name, number, names_list, saver):\n",
    "\n",
    "    lowercase_name = name.lower()\n",
    "\n",
    "    # Search to find 'rct' or 'w' with a number\n",
    "    if ('rct' in lowercase_name or 'w' in lowercase_name) and re.search(r'\\d', name):\n",
    "        saver = name\n",
    "\n",
    "    elif 'wk..' in lowercase_name and not re.search(r'\\d', name):\n",
    "        saver = name\n",
    "\n",
    "    # Check if 'w' is in 'j' and the next element in 'sep_names' is an integer\n",
    "    elif 'w' in lowercase_name and number + 1 < len(names_list) and not re.search(r'\\d', name):\n",
    "\n",
    "        if '2.0' not in names_list[number + 1] and '2,' not in names_list[number + 1]:\n",
    "            saver = name + str(names_list[number + 1])\n",
    "\n",
    "    elif re.search('rct.*[..]|rct.*[#]', lowercase_name) and not re.search(r'\\d', name):\n",
    "        saver = name\n",
    "    \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return saver    \n",
    "    \n",
    "def get_hd_fov(name, hd_fov):\n",
    "\n",
    "    lowercase_name = name.lower()\n",
    "    # Search whether there is 'hd' or 'fov' in j\n",
    "    if 'hd' in lowercase_name or 'fov' in lowercase_name:\n",
    "        hd_fov = 1 \n",
    "    \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return hd_fov\n",
    "\n",
    "def get_fraction(name, fraction):\n",
    "\n",
    "    lowercase_name = name.lower()\n",
    "\n",
    "    # Find the fraction number\n",
    "    if 'rct' in lowercase_name and re.search(r'\\d', name):\n",
    "        fraction = int(re.findall(r'\\d+', name)[0])\n",
    "    \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return fraction\n",
    "\n",
    "def get_date_information(image):\n",
    "\n",
    "    # Extract the date, the week day, and the week number from study date time\n",
    "    try:\n",
    "        study_datetime_CT = datetime.strptime(image[Tag(0x00080020)].value ,\"%Y%m%d\")\n",
    "        date_info = study_datetime_CT.date()\n",
    "        weekday = study_datetime_CT.weekday() + 1\n",
    "        week_num = study_datetime_CT.isocalendar()[1] #week\n",
    "\n",
    "    except:\n",
    "        date_info = None\n",
    "        weekday = None\n",
    "        week_num = None \n",
    "    \n",
    "    return date_info, weekday, week_num\n",
    "\n",
    "def get_slice_thickness(image):\n",
    "    \n",
    "    # Extract slice thickness\n",
    "    try:\n",
    "        slice_thickness = image['00180050'].value\n",
    "    except:\n",
    "        slice_thickness = None\n",
    "    \n",
    "    return slice_thickness\n",
    "\n",
    "def get_contrast(image):\n",
    "    \n",
    "    # Extract contrast information\n",
    "    try:\n",
    "        image[Tag(0x00180010)].value\n",
    "        contrast=1\n",
    "\n",
    "    except:\n",
    "        contrast=0\n",
    "    \n",
    "    return contrast\n",
    "\n",
    "def get_pixel_spacing(image):\n",
    "\n",
    "    # Extract pixel spacing\n",
    "    try:\n",
    "        pixel_spacing = image[Tag(0x00280030)].value\n",
    "    except:\n",
    "        pixel_spacing = None\n",
    "    \n",
    "    return pixel_spacing\n",
    "\n",
    "def get_ref_uid(image):\n",
    "\n",
    "    # Extract UID\n",
    "    try:\n",
    "        uid = image['00200052'].value\n",
    "    except:\n",
    "        uid = None\n",
    "    \n",
    "    return uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "def navigate_folder(path_folder, output_path, file_name):\n",
    "\n",
    "    # Add in config\n",
    "    exclusion_set = {'detail', 'ac_ct', 'ld_ct', 'ld ct', 'ac ct'} # CONFIG File\n",
    "    min_slice_num = 50 # CONFIG File\n",
    "    modality = 'CT' # CONFIG File\n",
    "\n",
    "    # Make a group to save all the information\n",
    "    group = list()\n",
    "\n",
    "    for r, d, f in os.walk(path_folder):\n",
    "        # make a list from all the directories \n",
    "        subfolders = [os.path.join(r, folder) for folder in d]\n",
    "\n",
    "        for subf in subfolders:\n",
    "            # number of slices (images) in each DICOM folder, and the name of the folders\n",
    "            slice_num = len(glob.glob(subf+\"/*.DCM\"))\n",
    "\n",
    "            # find whether subf is a path and the number of .DCM images is more than 50\n",
    "            if slice_num > min_slice_num:\n",
    "\n",
    "                # Extract the information of the image \n",
    "                image=pdcm.dcmread(glob.glob(subf+\"/*.DCM\")[0],force=True)\n",
    "                folder_name = get_folder_name(image, subf)\n",
    "    \n",
    "                # Extract the CTs\n",
    "                if image.Modality == modality and all(keyword not in folder_name.lower() for keyword in exclusion_set):\n",
    "   \n",
    "                    patient_id = get_patient_id(image)\n",
    "\n",
    "                    # split the name of the folder into strings of information\n",
    "                    names_list = folder_name.split()\n",
    "\n",
    "                    # Initialize the following three patameters\n",
    "                    saver = None\n",
    "                    hd_fov = 0\n",
    "                    fraction = None\n",
    "\n",
    "                    for number, name in enumerate(names_list):\n",
    "                        saver = get_probable_weklyct_name(name, number, names_list, saver) \n",
    "                        hd_fov = get_hd_fov(name, hd_fov)\n",
    "                        fraction = get_fraction(name, fraction)\n",
    "\n",
    "                    # Find different information\n",
    "                    date_info, weekday, week_num = get_date_information(image)\n",
    "                    slice_thickness = get_slice_thickness(image)\n",
    "                    contrast = get_contrast(image)\n",
    "                    pixel_spacing = get_pixel_spacing(image)\n",
    "                    uid = get_ref_uid(image)\n",
    "\n",
    "                    # Add the information of this group to the total dataset\n",
    "                    group.append({\n",
    "                                'ID': patient_id, 'folder_name': folder_name, 'date': date_info,\n",
    "                                'week_day': weekday, 'week_num': week_num, 'info_header': saver,\n",
    "                                'fraction': fraction, 'HD_FoV': hd_fov, 'slice_thickness': slice_thickness,\n",
    "                                'num_slices': slice_num, 'pixel_spacing': pixel_spacing, 'contrast': contrast,\n",
    "                                'UID': uid, 'path': subf\n",
    "                                })\n",
    "    \n",
    "    # Make a datafrme from the main folder\n",
    "    df = pd.DataFrame(group)\n",
    "\n",
    "    # Save the dataframe\n",
    "    df.to_csv(os.path.join(output_path,file_name), index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_folder = '//zkh/appdata/RTDicom/Projectline_HNC_modelling/OPC_data/ART_DATA1'\n",
    "output_path = '//zkh/appdata/RTDicom/Projectline_HNC_modelling/OPC_data/ART_DATA1'\n",
    "file_name = 'output.csv'\n",
    "df = navigate_folder(path_folder, output_path, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our knowledge about weeklyCTs, we know that they are only available after 2014, so we can just remove the patients before this specific time. Moreover, since this program just navigate all the folders, there may be some duplicated data in those folders, so I need to erase them from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df):\n",
    "    \"\"\"\n",
    "    clean the dataset\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Slice the part of the dataset after the mentioned time.\n",
    "    time_limit = pd.Timestamp('2014-01-01') # CONFIG File\n",
    "    df_copy = df_copy[pd.to_datetime(df_copy.date) > time_limit]\n",
    "\n",
    "    # Drop the doplicated folders\n",
    "    df_copy = df_copy.drop_duplicates(subset=['ID', 'folder_name', 'date'],\n",
    "                                       keep='first', inplace=False, ignore_index=True)\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this stage, I will drop all the remained CTs that are not WeeklyCTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_firstday(df, date_list):\n",
    "    try:\n",
    "        first_day = df[df.date == date_list[1]].iloc[0].week_day\n",
    "    except:\n",
    "        first_day = None\n",
    "    \n",
    "    return first_day\n",
    "\n",
    "def find_matching_header(info_headers):\n",
    "    for header in info_headers:\n",
    "        try:\n",
    "            lowercase_header = header.lower()\n",
    "\n",
    "            if any(keyword in lowercase_header for keyword in ['rct', 'w']) and re.search(r'\\d', header):\n",
    "                return header\n",
    "\n",
    "            elif 'wk..' in lowercase_header and not re.search(r'\\d', header):\n",
    "                return header\n",
    "\n",
    "            elif re.search(r'rct.*[..]|rct.*[#]', lowercase_header) and not re.search(r'\\d', header):\n",
    "                return header\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An exception occurred: {e}\")\n",
    "\n",
    "    return None\n",
    "\n",
    "def get_weeklycts_names(df, date_list):\n",
    "\n",
    "    header_list = list()\n",
    "\n",
    "    # Find the headers\n",
    "    for session in date_list[1:]:\n",
    "        info_headers = df[df.date == session].info_header.tolist()\n",
    "        header = find_matching_header(info_headers)\n",
    "\n",
    "        header_list.append(header)\n",
    "\n",
    "    # Ensure the header_list has 9 elements\n",
    "    header_list += [None] * (9 - len(header_list))\n",
    "\n",
    "    return header_list\n",
    "\n",
    "def get_accelerated_rt(patient_id, clinical_df):\n",
    "    try:\n",
    "        accelerated_rt = clinical_df[clinical_df.UMCG==int(patient_id)].Modality_adjusted.values[0]\n",
    "    \n",
    "    except:\n",
    "        accelerated_rt = 'Not Mentioned'\n",
    "    \n",
    "    return accelerated_rt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weeklyct_folders(df, output_path, file_name):\n",
    "    \"\"\"\n",
    "    This function finds weeklyCTs and drops other types of CTs\n",
    "    \"\"\"\n",
    "    # Call clinical df to extract Accelerated program for each patient\n",
    "    clinical_df_path = '//zkh/appdata/RTDicom/Projectline_HNC_modelling/OPC_data/ART Hooman/Xerostomia_dataset.xlsx' # CONFIG File\n",
    "    clinical_df = pd.read_excel(clinical_df_path)\n",
    "\n",
    "    group = list()\n",
    "\n",
    "    # Separate each ID dataframe\n",
    "    id_df = pd.DataFrame(df.groupby(['ID']))\n",
    "\n",
    "    for counter, id_num in enumerate(id_df[0]):\n",
    "\n",
    "        df = id_df[1][counter]\n",
    "\n",
    "        # Extract the parts suspected to contain weeklyCTs\n",
    "        df = df[(df['folder_name'].str.lower().str.contains('rct') & (df['date'] != df['date'].min())) \\\n",
    "                | ((df['date'] == df['date'].min()))]\n",
    "       \n",
    "        date_list = sorted(list(df.date.unique())) # Find the list of dates\n",
    "        rtstart = date_list[0] # Extract RTSTART  \n",
    "        first_day = get_firstday(df, date_list) # the week day of the first treatment\n",
    "\n",
    "        # Extract the weeklyCTs names and first day of the treatment\n",
    "        header_list= get_weeklycts_names(df, date_list)\n",
    "\n",
    "        # Extract other parameters\n",
    "        durations = date_list[1:]\n",
    "        weekly_ct_num = len(durations)       \n",
    "        durations += [None] * (9 - len(durations)) # Ensure it has 9 elements\n",
    "        Modality_adjusted = get_accelerated_rt(id_num, clinical_df)\n",
    "\n",
    "        group.append({'ID': int(id_num), 'Baseline': rtstart, 'Session1': durations[0],\n",
    "                        'Session2': durations[1], 'Session3': durations[2],'Session4': durations[3],\n",
    "                        'Session5': durations[4], 'Session6': durations[5],'Session7': durations[6],\n",
    "                        'Session8': durations[7],'Session9': durations[8], 'Fraction1': header_list[0],\n",
    "                        'Fraction2': header_list[1], 'Fraction3': header_list[2],'Fraction4': header_list[3],\n",
    "                        'Fraction5': header_list[4], 'Fraction6': header_list[5], 'Fraction7': header_list[6],\n",
    "                        'Fraction8': header_list[7],'Fraction9': header_list[8], 'First_day': first_day,\n",
    "                        'Number_of_CTs': df.shape[0], 'Number_of_weeklyCTs': weekly_ct_num, 'Modality_adjusted':Modality_adjusted})\n",
    "        \n",
    "    # Make a datafrme from the main folder\n",
    "    df_final = pd.DataFrame(group)\n",
    "\n",
    "    # Drop the patients who does not have weeklyCTs\n",
    "    df_final = df_final[~(df_final.Number_of_weeklyCTs == 0)]\n",
    "    df_final = df_final.reset_index().drop(columns=['index'])\n",
    "\n",
    "    # Save the dataframe\n",
    "    df_final.to_csv(os.path.join(output_path, file_name), index=False)\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_file_name = 'weeklyct_output.csv'\n",
    "weeklyct_df = extract_weeklyct_folders(df, output_path, weekly_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last step of Navigation Phase, I will replace all the strings in the header part of the dataframe into fraction numbers. There are multiple conditions here. some patients have their own fractions in their headers e.g. 'rct13', but some others have week number like 'wk3' or have a part of the repeated CT name such as 'rct..', 'wk', 'wk..', and so on. for the first group, I just use the number of fractions in the header. However, for the second and third group, I calculate the probable numeber of fractions using the following criteria.\n",
    "if the patient has accelarated RT plan, I assume that they should get 1.2 fraction per day (only in working days), so it mean 6 fractions per week.Ans, for patients with other types of the treatment, I suppose that they  should get 1 fraction per working day, so in total 5 per week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to extract numbers only if 'wk' is not present\n",
    "def extract_numbers(text):\n",
    "    if isinstance(text, str) and 'wk' not in text and re.search(r'\\d', text):\n",
    "        \n",
    "        return  float(''.join(filter(str.isdigit, text)))       \n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def get_existing_fractions(df):\n",
    "    \"\"\"\n",
    "    This function extract all the fractions exist in the data itself.\n",
    "    \"\"\"\n",
    "    for header in df.iloc[:, 11:20].columns:\n",
    "        df[header] = df[header].apply(extract_numbers)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_coef(Modality_adjusted):\n",
    "    \"\"\"\n",
    "    Get the coefficient of the fractions\n",
    "    \"\"\"\n",
    "    accelerated_list = ['Accelerated RT', 'Bioradiation'] # CONFIG File\n",
    "    not_accelerated_list = ['Chemoradiation', 'Conventional RT'] # CONFIG File\n",
    "    \n",
    "    if Modality_adjusted in not_accelerated_list:\n",
    "        coef = 1.0\n",
    "    \n",
    "    elif Modality_adjusted in accelerated_list:\n",
    "        coef = 1.2\n",
    "\n",
    "    else:\n",
    "        coef = 0.0\n",
    "\n",
    "    return coef\n",
    "\n",
    "def calculate_fraction(raw, fraction, fraction_num, coef, counter):\n",
    "    try:\n",
    "    \n",
    "        if isinstance(fraction, str) and 'wk' in fraction and  counter == 0:\n",
    "            fraction_num = (len(pd.bdate_range( raw[f'Baseline'], raw[f'Session{1}'])) - 1) * coef + 1\n",
    "\n",
    "        elif isinstance(fraction, str) and 'wk' in fraction and  counter != 0:\n",
    "            fraction_num += (len(pd.bdate_range( raw[f'Session{counter}'], raw[f'Session{counter+1}'])) - 1) * coef\n",
    "                \n",
    "        elif isinstance(fraction, str) and 'wk' not in fraction and not re.search(r'\\d', fraction) and counter==0:\n",
    "            fraction_num += (len(pd.bdate_range( raw[f'Baseline'], raw[f'Session{1}'])) - 1) * coef + 1\n",
    "\n",
    "        # This part does not work  if the rct.. or rct# is seperated from other part\n",
    "        elif isinstance(fraction, str) and 'wk' not in fraction and not re.search(r'\\d', fraction) and counter!=0:\n",
    "            fraction_num += (len(pd.bdate_range( raw[f'Session{counter}'], raw[f'Session{counter+1}'])) - 1) * coef\n",
    "\n",
    "        elif fraction is np.nan and counter < raw.Number_of_weeklyCTs and counter==0:\n",
    "            fraction_num = (len(pd.bdate_range( raw[f'Baseline'], raw[f'Session{1}'])) - 1) * coef + 1\n",
    "\n",
    "        elif fraction is np.nan and counter < raw.Number_of_weeklyCTs and counter!=0:\n",
    "            fraction_num += (len(pd.bdate_range( raw[f'Session{counter}'], raw[f'Session{counter+1}'])) - 1) * coef              \n",
    "\n",
    "        elif isinstance(fraction, int) or isinstance(fraction, float):\n",
    "            fraction_num = fraction\n",
    "\n",
    "        else:\n",
    "            fraction_num = None\n",
    "        return fraction_num \n",
    "\n",
    "    except:\n",
    "        return fraction_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fractions(df, output_path, file_name):\n",
    "    \"\"\"\n",
    "    This function finds or calculates all the fractions\n",
    "    \"\"\"\n",
    "    # Make a copy of the dataset\n",
    "    df_copy = df.copy()\n",
    "    coef_list = list()\n",
    "    # Find all the existing fractions in the dataset\n",
    "    df_copy = get_existing_fractions(df_copy)\n",
    "\n",
    "    # Iterate through patients\n",
    "    for index, raw in df_copy.iterrows():\n",
    "\n",
    "        fraction_list = list()\n",
    "        fraction_num = 0\n",
    "\n",
    "        # Calculate the coefficient\n",
    "        coef = get_coef(raw.Modality_adjusted)\n",
    "\n",
    "        # Iterate through fractions\n",
    "        for counter, fraction in enumerate(raw.iloc[11:20]):\n",
    "\n",
    "            # Calculate and add different fractions to the list of fractions\n",
    "            fraction_num = calculate_fraction(raw, fraction, fraction_num, coef, counter)\n",
    "            fraction_list.append(fraction_num)\n",
    "\n",
    "        df_copy.iloc[index, 11:20] = fraction_list\n",
    "        coef_list.append(coef)\n",
    " \n",
    "    df_copy['Coefficient'] = coef_list\n",
    "\n",
    "    # Save the dataframe\n",
    "    df_copy.to_csv(os.path.join(output_path, file_name), index=False)\n",
    "\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'Final_weeklyCT_df.xlsx'\n",
    "weeklyct_df = add_fractions(weeklyct_df, output_path, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last part of the first phase can be extracting the information of a specific week e.g. week3. To achieve this aim, I will make a function, that can be call and return an excel file for patients who have a specific week fraction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_week_information(main_df, weeklyct_df, week_name):\n",
    "\n",
    "    accelerated_list = ['Accelerated RT', 'Bioradiation'] # CONFIG File\n",
    "    not_accelerated_list = ['Chemoradiation', 'Conventional RT'] # CONFIG File\n",
    "    fraction_range_dict = {'week1':{'not_accelerated':[0.9, 5.0],  'accelerated': [0.9, 6.0]}, # Config File\n",
    "                           'week2':{'not_accelerated':[5.0, 10.0],  'accelerated': [6.0, 12.0]},\n",
    "                           'week3':{'not_accelerated':[10.0, 15.0],  'accelerated': [12.0, 18.0]},\n",
    "                           'week4':{'not_accelerated':[15.0, 20.0],  'accelerated': [18.0, 24.0]},\n",
    "                           'week5':{'not_accelerated':[20.0, 25.0],  'accelerated': [24.0, 30.0]},\n",
    "                           'week6':{'not_accelerated':[25.0, 30.0],  'accelerated': [30.0, 36.0]},\n",
    "                           'week7':{'not_accelerated':[30.0, 35.0],  'accelerated': [36.0, 42.0]},\n",
    "                           'week8':{'not_accelerated':[35.0, 40.0],  'accelerated': [42.0, 48.0]}}\n",
    "    week_list = list()\n",
    "\n",
    "    # Iterate through patients\n",
    "    for _, raw in weeklyct_df.iterrows():\n",
    "        matching_list = []\n",
    "        fraction_seri = raw.iloc[11:20]\n",
    "\n",
    "        # Find any columns that have values inside the range of a a specific week\n",
    "        if raw.Modality_adjusted in not_accelerated_list:\n",
    "            matching_list = [column for column in fraction_seri.index \\\n",
    "            if (raw[column]is not None and raw[column] > fraction_range_dict[week_name]['not_accelerated'][0] \\\n",
    "                and raw[column] <= fraction_range_dict[week_name]['not_accelerated'][1])]\n",
    "\n",
    "        elif raw.Modality_adjusted in accelerated_list:\n",
    "            matching_list = [column for column in fraction_seri.index \\\n",
    "            if (raw[column]is not None and raw[column] > fraction_range_dict[week_name]['accelerated'][0] \\\n",
    "                and raw[column] <= fraction_range_dict[week_name]['accelerated'][1])]\n",
    "\n",
    "        # If finds a column, add some information of  that patient to the dictionary\n",
    "        if len(matching_list) > 0:\n",
    "            week_num = matching_list[0][-1]\n",
    "            week_list = [{'ID': raw.ID,\n",
    "                         'date': raw[f'Session{week_num}'],\n",
    "                         'Fraction_num': matching_list[0], \n",
    "                         'Fraction_magnitude': raw[matching_list[0]], \n",
    "                         'Modality_adjusted': raw.Modality_adjusted}]\n",
    "\n",
    "    # Make a datafrme from the main folder\n",
    "    week_df = pd.DataFrame(week_list)\n",
    "    final_df = week_df.merge(main_df, on=['ID', 'date']).drop(columns=['fraction'])\n",
    "    \n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_df = get_a_week_information(df, weeklyct_df, 'week6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '//zkh/appdata/RTDicom/Projectline_HNC_modelling/Users/Hooman Bahrdo/Models/Deep_Learning/DL_NTCP_Xerostomia/datasets/dataset_old_v2/stratified_sampling_test_manual_94.csv'\n",
    "\n",
    "dff = pd.read_csv(path, sep=';').drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.age = dff.age / 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.to_csv(path, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radiomics_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
