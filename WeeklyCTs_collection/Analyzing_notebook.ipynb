{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this notebook, I will describe all the steps that I have taken to make a new dataset for Weekly CTs.\n",
    "\n",
    "Basically, the process contains five different steps:\n",
    "\n",
    "1. Navigation of the folder in which one think there maybe any weeklyCTs. These folders can be on this computer or a user can just make these folders by downloading new patients from MIRADA or other UMCG datasets.\n",
    "\n",
    "2. Extracting only weeklyCTs from these folders and make an excel file from them.\n",
    "\n",
    "3. Transferring the new-founded weeklyCTs into a destination folder (it can be an existing folder for the weeklyCTs or a new folder).\n",
    "\n",
    "4. Making a report excel file of some information about the weeklyCTs in the destination file and some clinical information from the patients who have these weeklyCTs.\n",
    "\n",
    "5. Making a pannel that contains different information about the WeeklyCT dataset.\n",
    "\n",
    "6. A Watchdog is keep the track of all the additions to the destination folder, and save them in a log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from datetime import time, datetime, date\n",
    "\n",
    "# DICOM Libraries\n",
    "import pydicom as pdcm\n",
    "from pydicom.tag import Tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Navigation Phase\n",
    "### DICOM Files\n",
    "All kinds of CTs were stored in the form of DICOM files. DICOM, which stands for Digital Imaging and Communications in Medicine, is a standard for transmitting, storing, and sharing medical images. DICOM files contain information about medical images, such as X-rays, CT scans, MRIs, and ultrasound. This standard ensures the interoperability of medical imaging equipment from different manufacturers. Some key features are:\n",
    "\n",
    "**Metadata:** DICOM files store not only the pixel data of the medical images but also a wealth of metadata. This metadata includes patient information, imaging device details, acquisition parameters, and more.\n",
    "\n",
    "**Interoperability:** DICOM enables the exchange of medical images and related information between different devices and systems. This interoperability is crucial in healthcare settings where various imaging modalities and equipment are used.\n",
    "\n",
    "**Structured Data:** DICOM files use a structured format for information, allowing for consistency and ease of interpretation by different systems. This makes it possible for healthcare professionals to access and understand the data regardless of the equipment used to capture or generate the images.\n",
    "\n",
    "For information of different tags and the definitions one can use the following links: [Wiki](https://en.wikipedia.org/wiki/DICOM), [link](https://dicom.innolitics.com/ciods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_name(image, subf):\n",
    "\n",
    "    # find the name of the folder\n",
    "    try:\n",
    "        folder_name = image[Tag(0x0008103e)].value\n",
    "\n",
    "    except:\n",
    "        study = image[Tag(0x00081030)].value\n",
    "        patient_id = image[Tag(0x00100020)].value\n",
    "        print(f'Warning: folder {study} with {patient_id} ID does NOT have Series Description')\n",
    "        folder_name = subf.split('\\\\')[-1]  \n",
    "\n",
    "    return folder_name\n",
    "\n",
    "def get_patient_id(image):\n",
    "\n",
    "    # Extract the patient ID\n",
    "    try:\n",
    "        patient_id = image[Tag(0x00100020)].value\n",
    "\n",
    "    except:\n",
    "        print(f'Warning: There is NO patient ID')\n",
    "        patient_id = None\n",
    "\n",
    "    return patient_id\n",
    "\n",
    "def get_probable_weklyct_name(name, number, names_list):\n",
    "\n",
    "    lowercase_name = name.lower()\n",
    "\n",
    "    # Search to find 'rct' or 'w' with a number\n",
    "    if ('rct' in lowercase_name or 'w' in lowercase_name) and re.search(r'\\d', name):\n",
    "        saver = name\n",
    "\n",
    "    elif 'wk..' in lowercase_name and not re.search(r'\\d', name):\n",
    "        saver = name\n",
    "\n",
    "    # Check if 'w' is in 'j' and the next element in 'sep_names' is an integer\n",
    "    elif 'w' in lowercase_name and number + 1 < len(names_list) and not re.search(r'\\d', name):\n",
    "\n",
    "        if '2.0' not in names_list[number + 1] and '2,' not in names_list[number + 1]:\n",
    "            saver = name + str(names_list[number + 1])\n",
    "\n",
    "    elif re.search('rct.*[..]|rct.*[#]', lowercase_name) and not re.search(r'\\d', name):\n",
    "        saver = name\n",
    "    \n",
    "    else:\n",
    "        saver = None \n",
    "\n",
    "    return saver    \n",
    "    \n",
    "def get_hd_fov(name):\n",
    "\n",
    "    lowercase_name = name.lower()\n",
    "    # Search whether there is 'hd' or 'fov' in j\n",
    "    if 'hd' in lowercase_name or 'fov' in lowercase_name:\n",
    "        hd_fov = 1 \n",
    "    \n",
    "    else:\n",
    "        hd_fov = 0\n",
    "    \n",
    "    return hd_fov\n",
    "\n",
    "def get_fraction(name):\n",
    "\n",
    "    lowercase_name = name.lower()\n",
    "\n",
    "    # Find the fraction number\n",
    "    if 'rct' in lowercase_name and re.search(r'\\d', name):\n",
    "        fraction = int(re.findall(r'\\d+', name)[0])\n",
    "    \n",
    "    else:\n",
    "        fraction = None\n",
    "    \n",
    "    return fraction\n",
    "\n",
    "def get_date_information(image):\n",
    "\n",
    "    # Extract the date, the week day, and the week number from study date time\n",
    "    try:\n",
    "        study_datetime_CT = datetime.strptime(image[Tag(0x00080020)].value ,\"%Y%m%d\")\n",
    "        date_info = study_datetime_CT.date()\n",
    "        weekday = study_datetime_CT.weekday() + 1\n",
    "        week_num = study_datetime_CT.isocalendar().week\n",
    "    except:\n",
    "        date_info = None\n",
    "        weekday = None\n",
    "        week_num = None \n",
    "    \n",
    "    return date_info, weekday, week_num\n",
    "\n",
    "def get_slice_thickness(image):\n",
    "    \n",
    "    # Extract slice thickness\n",
    "    try:\n",
    "        slice_thickness = image['00180050'].value\n",
    "    except:\n",
    "        slice_thickness = None\n",
    "    \n",
    "    return slice_thickness\n",
    "\n",
    "def get_contrast(image):\n",
    "\n",
    "    # Extract contrast information\n",
    "    try:\n",
    "        image[Tag(0x00180010)].value\n",
    "        contrast=1\n",
    "\n",
    "    except:\n",
    "        contrast=0\n",
    "    \n",
    "    return contrast\n",
    "\n",
    "def get_pixel_spacing(image):\n",
    "\n",
    "    # Extract pixel spacing\n",
    "    try:\n",
    "        pixel_spacing = image[Tag(0x00280030)].value\n",
    "    except:\n",
    "        pixel_spacing = None\n",
    "    \n",
    "    return pixel_spacing\n",
    "\n",
    "def get_ref_uid(image):\n",
    "\n",
    "    # Extract UID\n",
    "    try:\n",
    "        uid = image['00200052'].value\n",
    "    except:\n",
    "        uid = None\n",
    "    \n",
    "    return uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def navigate_folder(path_folder, output_path, file_name):\n",
    "\n",
    "    # Add in config\n",
    "    exclusion_set = {'detail', 'ac_ct', 'ld_ct', 'ld ct', 'ac ct'} # CONFIG File\n",
    "    min_slice_num = 50 # CONFIG File\n",
    "    modality = 'CT' # CONFIG File\n",
    "\n",
    "    # Make a group to save all the information\n",
    "    group = list()\n",
    "\n",
    "    for r, d, f in os.walk(path_folder):\n",
    "        # make a list from all the directories \n",
    "        subfolders = [os.path.join(r, folder) for folder in d]\n",
    "\n",
    "        for subf in subfolders:\n",
    "            # number of slices (images) in each DICOM folder, and the name of the folders\n",
    "            slice_num = len(glob.glob(subf+\"/*.DCM\"))\n",
    "\n",
    "            # find whether subf is a path and the number of .DCM images is more than 50\n",
    "            if slice_num > min_slice_num:\n",
    "\n",
    "                # Extract the information of the image \n",
    "                image=pdcm.dcmread(glob.glob(subf+\"/*.DCM\")[0],force=True)\n",
    "                folder_name = get_folder_name(image, subf)\n",
    "    \n",
    "                # Extract the CTs\n",
    "                if image.Modality == modality and all(keyword not in folder_name.lower() for keyword in exclusion_set):\n",
    "   \n",
    "                    patient_id = get_patient_id(image)\n",
    "\n",
    "                    # split the name of the folder into strings of information\n",
    "                    names_list = folder_name.split()\n",
    "            \n",
    "                    print(patient_id, folder_name)\n",
    "\n",
    "                    # Find different information\n",
    "                    for number, name in enumerate(names_list):\n",
    "                        saver = get_probable_weklyct_name(name, number, names_list) \n",
    "                        hd_fov = get_hd_fov(name)\n",
    "                        fraction = get_fraction(name)\n",
    "\n",
    "                    date_info, weekday, week_num = get_date_information(image)\n",
    "                    slice_thickness = get_slice_thickness(image)\n",
    "                    contrast = get_contrast(image)\n",
    "                    pixel_spacing = get_pixel_spacing(image)\n",
    "                    uid = get_ref_uid(image)\n",
    "\n",
    "                    # Add the information of this group to the total dataset\n",
    "                    group.append({\n",
    "                                'ID': patient_id, 'folder_name': folder_name, 'date': date_info,\n",
    "                                'week_day': weekday, 'week_num': week_num, 'info_header': saver,\n",
    "                                'fraction': fraction, 'HD_FoV': hd_fov, 'slice_thickness': slice_thickness,\n",
    "                                'num_slices': slice_num, 'pixel_spacing': pixel_spacing, 'contrast': contrast,\n",
    "                                'UID': uid, 'path': subf\n",
    "                                })\n",
    "    \n",
    "    # Make a datafrme from the main folder\n",
    "    df = pd.DataFrame(group)\n",
    "\n",
    "    # Save the dataframe\n",
    "    df.to_csv(os.path.join(output_path,file_name), index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_folder = '//zkh/appdata/RTDicom/Projectline_HNC_modelling/OPC_data/DICOM_data_organized'\n",
    "output_path = '//zkh/appdata/RTDicom/Projectline_HNC_modelling/OPC_data/DICOM_data_organized'\n",
    "file_name = 'output.csv'\n",
    "df = navigate_folder(path_folder, output_path, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our knowledge about weeklyCTs, we know that they are only available after 2014, so we can just remove the patients before this specific time. Moreover, since this program just navigate all the folders, there may be some duplicated data in those folders, so I need to erase them from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df):\n",
    "    \"\"\"\n",
    "    clean the dataset\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Slice the part of the dataset after the mentioned time.\n",
    "    time_limit = pd.Timestamp('2014-01-01') # CONFIG File\n",
    "    df_copy = df_copy[pd.to_datetime(df_copy.date) < time_limit]\n",
    "\n",
    "    # Drop the doplicated folders\n",
    "    df_copy = df_copy.drop_duplicates(subset=['ID', 'folder_name', 'date'],\n",
    "                                       keep='first', inplace=False, ignore_index=True)\n",
    "    \n",
    "    # Erase the hours from 'date' column\n",
    "    new_date_column = pd.Series([duration.date() for duration in df_copy.date])\n",
    "    df_copy['date'] = new_date_column\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this stage, I will drop all the remained CTs that are not WeeklyCTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_header(info_headers):\n",
    "    for header in info_headers:\n",
    "        try:\n",
    "            lowercase_header = header.lower()\n",
    "\n",
    "            if any(keyword in lowercase_header for keyword in ['rct', 'w']) and re.search(r'\\d', header):\n",
    "                return header\n",
    "\n",
    "            elif 'wk..' in lowercase_header and not re.search(r'\\d', header):\n",
    "                return header\n",
    "\n",
    "            elif re.search(r'rct.*[..]|rct.*[#]', lowercase_header) and not re.search(r'\\d', header):\n",
    "                return header\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An exception occurred: {e}\")\n",
    "\n",
    "    return None\n",
    "\n",
    "def get_weeklycts_names(df, date_list):\n",
    "\n",
    "    header_list = list()\n",
    "\n",
    "    # Find the headers\n",
    "    for session in date_list[1:]:\n",
    "        info_headers = df[df.date == session].info_header.tolist()\n",
    "        header = find_matching_header(info_headers)\n",
    "\n",
    "        header_list.append(header)\n",
    "\n",
    "    # Ensure the header_list has 9 elements\n",
    "    header_list += [None] * (9 - len(header_list))\n",
    "\n",
    "    return header_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weeklyct_folders(df, output_path, file_name):\n",
    "    \"\"\"\n",
    "    This function finds weeklyCTs and drops other types of CTs\n",
    "    \"\"\"\n",
    "    group = list()\n",
    "\n",
    "    # Separate each ID dataframe\n",
    "    id_df = pd.DataFrame(df.groupby(['ID']))\n",
    "\n",
    "    for counter, id_num in enumerate(id_df[0]):\n",
    "\n",
    "        df = id_df[1][counter]\n",
    "\n",
    "        # Extract the parts suspected to contain weeklyCTs\n",
    "        df = df[(df['folder_name'].str.lower().str.contains('rct') & (df['date'] != df['date'].min())) \\\n",
    "                | ((df['date'] == df['date'].min()))]\n",
    "       \n",
    "        date_list = sorted(list(df.date.unique())) # Find the list of dates\n",
    "        rtstart = date_list[0] # Extract RTSTART\n",
    "        first_day = df[df.date == date_list[1]].iloc[0].week_day # the week day of the first treatment\n",
    "\n",
    "        # Extract the weeklyCTs names and first day of the treatment\n",
    "        header_list= get_weeklycts_names(df, date_list)\n",
    "\n",
    "        # Extract other parameters\n",
    "        durations = date_list[1:]\n",
    "        weekly_ct_num = len(durations)       \n",
    "        durations += [None] * (9 - len(durations)) # Ensure it has 9 elements\n",
    "\n",
    "        group.append({'ID': id_num[0], 'Baseline': rtstart, 'Session1': durations[0],\n",
    "                        'Session2': durations[1], 'Session3': durations[2],'Session4': durations[3],\n",
    "                        'Session5': durations[4], 'Session6': durations[5],'Session7': durations[6],\n",
    "                        'Session8': durations[7],'Session9': durations[8], 'Fraction1': header_list[0],\n",
    "                        'Fraction2': header_list[1], 'Fraction3': header_list[2],'Fraction4': header_list[3],\n",
    "                        'Fraction5': header_list[4], 'Fraction6': header_list[5], 'Fraction7': header_list[6],\n",
    "                        'Fraction8': header_list[7],'Fraction9': header_list[8], 'First_day': first_day,\n",
    "                        'Number_of_CTs': df.shape[0], 'Number_of_weeklyCTs': weekly_ct_num})\n",
    "        \n",
    "    # Make a datafrme from the main folder\n",
    "    df_final = pd.DataFrame(group)\n",
    "\n",
    "    # Save the dataframe\n",
    "    df_final.to_csv(os.path.join(output_path, file_name), index=False)\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_file_name = 'weeklyct_output.csv'\n",
    "weeklyct_df = extract_weeklyct_folders(df, output_path, weekly_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last step of Navigation Phase, I will replace all the strings in the header part of the dataframe into fraction numbers. There are multiple conditions here. some patients have their own fractions in their headers e.g. 'rct13', but some others have week number like 'wk3' or have a part of the repeated CT name such as 'rct..', 'wk', 'wk..', and so on. for the first group, I just use the number of fractions in the header. However, for the second and third group, I calculate the probable numeber of fractions using the following criteria.\n",
    "if the patient has accelarated RT plan, I assume that they should get 1.2 fraction per day (only in working days), so it mean 6 fractions per week.Ans, for patients with other types of the treatment, I suppose that they  should get 1 fraction per working day, so in total 5 per week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to extract numbers only if 'wk' is not present\n",
    "def extract_numbers(text):\n",
    "    if isinstance(text, str) and 'wk' not in text and re.search(r'\\d', text):\n",
    "        \n",
    "        return  float(''.join(filter(str.isdigit, text)))       \n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def get_existing_fractions(df):\n",
    "    \"\"\"\n",
    "    This function extract all the fractions exist in the data itself.\n",
    "    \"\"\"\n",
    "    for header in df.iloc[:, 12:21].columns:\n",
    "        df[header] = df[header].apply(extract_numbers)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_coef(accelerated_rt):\n",
    "    \"\"\"\n",
    "    Get the coefficient of the fractions\n",
    "    \"\"\"\n",
    "    if accelerated_rt == 0:\n",
    "        coef = 1\n",
    "    else:\n",
    "        coef = 1.2\n",
    "    return coef\n",
    "\n",
    "def calculate_fraction(raw, fraction, fraction_num, coef, counter):\n",
    "    try:\n",
    "\n",
    "        if isinstance(fraction, str) and 'wk' in fraction and  counter == 0:\n",
    "            fraction_num = (len(pd.bdate_range( raw[f'RTSTART'], raw[f'Session{1}'])) - 1) * coef + 1\n",
    "\n",
    "        elif isinstance(fraction, str) and 'wk' in fraction and  counter != 0:\n",
    "            fraction_num += (len(pd.bdate_range( raw[f'Session{counter}'], raw[f'Session{counter+1}'])) - 1) * coef\n",
    "                \n",
    "        elif isinstance(fraction, str) and 'wk' not in fraction and not re.search(r'\\d', fraction) and counter==0:\n",
    "            fraction_num += (len(pd.bdate_range( raw[f'RTSTART'], raw[f'Session{1}'])) - 1) * coef + 1\n",
    "\n",
    "        # This part does not work  if the rct.. or rct# is seperated from other part\n",
    "        elif isinstance(fraction, str) and 'wk' not in fraction and not re.search(r'\\d', fraction) and counter!=0:\n",
    "            fraction_num += (len(pd.bdate_range( raw[f'Session{counter}'], raw[f'Session{counter+1}'])) - 1) * coef\n",
    "\n",
    "        elif fraction is np.nan and counter < raw.Number_of_weeklyCTs and counter==0:\n",
    "            fraction_num = (len(pd.bdate_range( raw[f'RTSTART'], raw[f'Session{1}'])) - 1) * coef + 1\n",
    "\n",
    "        elif fraction is np.nan and counter < raw.Number_of_weeklyCTs and counter!=0:\n",
    "            fraction_num += (len(pd.bdate_range( raw[f'Session{counter}'], raw[f'Session{counter+1}'])) - 1) * coef              \n",
    "\n",
    "        elif isinstance(fraction, int) or isinstance(fraction, float):\n",
    "            fraction_num = fraction\n",
    "\n",
    "        return fraction_num \n",
    "\n",
    "    except:\n",
    "        return fraction_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fractions(df, output_path, file_name):\n",
    "    \"\"\"\n",
    "    This function finds or calculates all the fractions\n",
    "    \"\"\"\n",
    "    # Make a copy of the dataset\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Find all the existing fractions in the dataset\n",
    "    df_copy = get_existing_fractions(df_copy)\n",
    "\n",
    "    # Iterate through patients\n",
    "    for index, raw in df_copy.iterrows():\n",
    "\n",
    "        fraction_list = list()\n",
    "        fraction_num = 0\n",
    "\n",
    "        # Calculate the coefficient\n",
    "        coef = get_coef(raw.accelerated_rt)\n",
    "\n",
    "        # Iterate through fractions\n",
    "        for counter, fraction in enumerate(raw.iloc[12:21]):\n",
    "\n",
    "            # Calculate and add different fractions to the list of fractions\n",
    "            fraction_num = calculate_fraction(raw, fraction, fraction_num, coef, counter)\n",
    "            fraction_list.append(fraction_num)\n",
    "\n",
    "        # for column_name in fraction_list.keys():\n",
    "        #     df_copy.loc[index, column_name] = fraction_list[column_name]\n",
    "        # Assign calculated fractions directly to result DataFrame\n",
    "            \n",
    "        df_copy.iloc[index, 12:21] = fraction_list\n",
    "\n",
    "    # Save the dataframe\n",
    "    df_copy.to_csv(os.path.join(output_path, file_name), index=False)\n",
    "\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'Final_weeklyCT_df.xlsx'\n",
    "weeklyct_df = add_fractions(weeklyct_df, output_path, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '//zkh/appdata/RTDicom/Projectline_HNC_modelling/Users/Hooman Bahrdo/Models/Deep_Learning/DL_NTCP_Xerostomia/datasets/dataset_old_v2/stratified_sampling_test_manual_94.csv'\n",
    "\n",
    "dff = pd.read_csv(path, sep=';').drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.age = dff.age / 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.to_csv(path, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>surface_bsl_dlc</th>\n",
       "      <th>surface_wk3_dlc</th>\n",
       "      <th>OAR</th>\n",
       "      <th>Contra_Dmean</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>Modality_adjusted</th>\n",
       "      <th>xer_bsl</th>\n",
       "      <th>Loctum2</th>\n",
       "      <th>...</th>\n",
       "      <th>delta_surf_dlc</th>\n",
       "      <th>xer_bsl_citor</th>\n",
       "      <th>xer_wk1_not_at_all</th>\n",
       "      <th>xer_wk1_little</th>\n",
       "      <th>xer_wk1_moderate_to_severe</th>\n",
       "      <th>xer_bsl_not_at_all</th>\n",
       "      <th>xer_bsl_little</th>\n",
       "      <th>xer_bsl_moderate_to_severe</th>\n",
       "      <th>sqr_parotid_Dmean</th>\n",
       "      <th>Split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20715</td>\n",
       "      <td>8108.746885</td>\n",
       "      <td>7070.864868</td>\n",
       "      <td>Parotid_R</td>\n",
       "      <td>17.946843</td>\n",
       "      <td>1</td>\n",
       "      <td>0.56</td>\n",
       "      <td>Chemoradiation</td>\n",
       "      <td>1</td>\n",
       "      <td>Oropharynx</td>\n",
       "      <td>...</td>\n",
       "      <td>10.378820</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.353827</td>\n",
       "      <td>train_val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21879</td>\n",
       "      <td>7874.630591</td>\n",
       "      <td>7585.310254</td>\n",
       "      <td>Parotid_R</td>\n",
       "      <td>26.628884</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "      <td>Chemoradiation</td>\n",
       "      <td>1</td>\n",
       "      <td>Oropharynx</td>\n",
       "      <td>...</td>\n",
       "      <td>2.893203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.298645</td>\n",
       "      <td>train_val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52277</td>\n",
       "      <td>7960.561507</td>\n",
       "      <td>7511.293366</td>\n",
       "      <td>Parotid_L</td>\n",
       "      <td>29.492172</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Chemoradiation</td>\n",
       "      <td>0</td>\n",
       "      <td>Oropharynx</td>\n",
       "      <td>...</td>\n",
       "      <td>4.492681</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.448122</td>\n",
       "      <td>train_val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59896</td>\n",
       "      <td>6660.874235</td>\n",
       "      <td>6301.546221</td>\n",
       "      <td>Parotid_L</td>\n",
       "      <td>30.214213</td>\n",
       "      <td>1</td>\n",
       "      <td>0.51</td>\n",
       "      <td>Chemoradiation</td>\n",
       "      <td>1</td>\n",
       "      <td>Oropharynx</td>\n",
       "      <td>...</td>\n",
       "      <td>3.593280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.256083</td>\n",
       "      <td>train_val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70426</td>\n",
       "      <td>6068.357955</td>\n",
       "      <td>5823.534682</td>\n",
       "      <td>Parotid_R</td>\n",
       "      <td>21.277559</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Conventional RT</td>\n",
       "      <td>1</td>\n",
       "      <td>Oropharynx</td>\n",
       "      <td>...</td>\n",
       "      <td>2.448233</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.156976</td>\n",
       "      <td>train_val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>9899837</td>\n",
       "      <td>6851.795819</td>\n",
       "      <td>6120.349395</td>\n",
       "      <td>Parotid_R</td>\n",
       "      <td>24.439093</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>Accelerated RT</td>\n",
       "      <td>1</td>\n",
       "      <td>Oropharynx</td>\n",
       "      <td>...</td>\n",
       "      <td>7.314464</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.281808</td>\n",
       "      <td>train_val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>9916161</td>\n",
       "      <td>6328.879356</td>\n",
       "      <td>6485.986032</td>\n",
       "      <td>Parotid_R</td>\n",
       "      <td>5.502483</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>Chemoradiation</td>\n",
       "      <td>1</td>\n",
       "      <td>Neus(bij)holte</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.571067</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.536815</td>\n",
       "      <td>train_val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>9946201</td>\n",
       "      <td>6701.471322</td>\n",
       "      <td>6357.803318</td>\n",
       "      <td>Parotid_R</td>\n",
       "      <td>13.855585</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>Bioradiation</td>\n",
       "      <td>0</td>\n",
       "      <td>Oropharynx</td>\n",
       "      <td>...</td>\n",
       "      <td>3.436680</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.422918</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>9956433</td>\n",
       "      <td>8802.968090</td>\n",
       "      <td>8901.740425</td>\n",
       "      <td>Parotid_R</td>\n",
       "      <td>15.743012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.66</td>\n",
       "      <td>Chemoradiation</td>\n",
       "      <td>1</td>\n",
       "      <td>Oropharynx</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987723</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.014044</td>\n",
       "      <td>train_val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>9980149</td>\n",
       "      <td>8528.602331</td>\n",
       "      <td>8988.751573</td>\n",
       "      <td>Parotid_R</td>\n",
       "      <td>0.020127</td>\n",
       "      <td>0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>Accelerated RT</td>\n",
       "      <td>1</td>\n",
       "      <td>Oropharynx</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.601492</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.259395</td>\n",
       "      <td>train_val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  surface_bsl_dlc  surface_wk3_dlc        OAR  Contra_Dmean  sex  \\\n",
       "0      20715      8108.746885      7070.864868  Parotid_R     17.946843    1   \n",
       "1      21879      7874.630591      7585.310254  Parotid_R     26.628884    1   \n",
       "2      52277      7960.561507      7511.293366  Parotid_L     29.492172    1   \n",
       "3      59896      6660.874235      6301.546221  Parotid_L     30.214213    1   \n",
       "4      70426      6068.357955      5823.534682  Parotid_R     21.277559    1   \n",
       "..       ...              ...              ...        ...           ...  ...   \n",
       "297  9899837      6851.795819      6120.349395  Parotid_R     24.439093    0   \n",
       "298  9916161      6328.879356      6485.986032  Parotid_R      5.502483    0   \n",
       "299  9946201      6701.471322      6357.803318  Parotid_R     13.855585    0   \n",
       "300  9956433      8802.968090      8901.740425  Parotid_R     15.743012    1   \n",
       "301  9980149      8528.602331      8988.751573  Parotid_R      0.020127    0   \n",
       "\n",
       "      age Modality_adjusted  xer_bsl         Loctum2  ...  delta_surf_dlc  \\\n",
       "0    0.56    Chemoradiation        1      Oropharynx  ...       10.378820   \n",
       "1    0.67    Chemoradiation        1      Oropharynx  ...        2.893203   \n",
       "2    0.50    Chemoradiation        0      Oropharynx  ...        4.492681   \n",
       "3    0.51    Chemoradiation        1      Oropharynx  ...        3.593280   \n",
       "4    0.75   Conventional RT        1      Oropharynx  ...        2.448233   \n",
       "..    ...               ...      ...             ...  ...             ...   \n",
       "297  0.54    Accelerated RT        1      Oropharynx  ...        7.314464   \n",
       "298  0.65    Chemoradiation        1  Neus(bij)holte  ...       -1.571067   \n",
       "299  0.65      Bioradiation        0      Oropharynx  ...        3.436680   \n",
       "300  0.66    Chemoradiation        1      Oropharynx  ...       -0.987723   \n",
       "301  0.64    Accelerated RT        1      Oropharynx  ...       -4.601492   \n",
       "\n",
       "     xer_bsl_citor  xer_wk1_not_at_all  xer_wk1_little  \\\n",
       "0                1                   0               1   \n",
       "1                1                   0               1   \n",
       "2                0                   1               0   \n",
       "3                1                   0               1   \n",
       "4                1                   1               0   \n",
       "..             ...                 ...             ...   \n",
       "297              2                   0               1   \n",
       "298              2                   0               0   \n",
       "299              0                   0               0   \n",
       "300              2                   0               1   \n",
       "301              2                   0               1   \n",
       "\n",
       "     xer_wk1_moderate_to_severe  xer_bsl_not_at_all  xer_bsl_little  \\\n",
       "0                             0                   0               1   \n",
       "1                             0                   0               1   \n",
       "2                             0                   1               0   \n",
       "3                             0                   0               1   \n",
       "4                             0                   0               1   \n",
       "..                          ...                 ...             ...   \n",
       "297                           0                   0               0   \n",
       "298                           1                   0               0   \n",
       "299                           1                   1               0   \n",
       "300                           0                   0               0   \n",
       "301                           0                   0               0   \n",
       "\n",
       "     xer_bsl_moderate_to_severe  sqr_parotid_Dmean      Split  \n",
       "0                             0           9.353827  train_val  \n",
       "1                             0          11.298645  train_val  \n",
       "2                             0          11.448122  train_val  \n",
       "3                             0          11.256083  train_val  \n",
       "4                             0          11.156976  train_val  \n",
       "..                          ...                ...        ...  \n",
       "297                           1          10.281808  train_val  \n",
       "298                           1           4.536815  train_val  \n",
       "299                           0          11.422918       test  \n",
       "300                           1          10.014044  train_val  \n",
       "301                           1           1.259395  train_val  \n",
       "\n",
       "[302 rows x 26 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.56\n",
      "0.67\n",
      "0.5\n",
      "0.51\n",
      "0.75\n",
      "0.48\n",
      "0.67\n",
      "0.63\n",
      "0.52\n",
      "0.55\n",
      "0.73\n",
      "0.69\n",
      "0.61\n",
      "0.65\n",
      "0.62\n",
      "0.54\n",
      "0.55\n",
      "0.5\n",
      "0.55\n",
      "0.62\n",
      "0.57\n",
      "0.53\n",
      "0.66\n",
      "0.72\n",
      "0.52\n",
      "0.72\n",
      "0.3\n",
      "0.61\n",
      "0.53\n",
      "0.69\n",
      "0.67\n",
      "0.45\n",
      "0.46\n",
      "0.63\n",
      "0.75\n",
      "0.49\n",
      "0.64\n",
      "0.54\n",
      "0.6\n",
      "0.79\n",
      "0.48\n",
      "0.58\n",
      "0.7\n",
      "0.59\n",
      "0.51\n",
      "0.71\n",
      "0.57\n",
      "0.67\n",
      "0.67\n",
      "0.73\n",
      "0.52\n",
      "0.62\n",
      "0.57\n",
      "0.63\n",
      "0.68\n",
      "0.79\n",
      "0.64\n",
      "0.51\n",
      "0.66\n",
      "0.49\n",
      "0.7\n",
      "0.55\n",
      "0.67\n",
      "0.53\n",
      "0.59\n",
      "0.69\n",
      "0.71\n",
      "0.63\n",
      "0.54\n",
      "0.53\n",
      "0.57\n",
      "0.78\n",
      "0.68\n",
      "0.68\n",
      "0.72\n",
      "0.61\n",
      "0.79\n",
      "0.76\n",
      "0.63\n",
      "0.57\n",
      "0.73\n",
      "0.71\n",
      "0.49\n",
      "0.53\n",
      "0.84\n",
      "0.76\n",
      "0.64\n",
      "0.71\n",
      "0.71\n",
      "0.71\n",
      "0.83\n",
      "0.47\n",
      "0.48\n",
      "0.6\n",
      "0.65\n",
      "0.59\n",
      "0.59\n",
      "0.66\n",
      "0.57\n",
      "0.7\n",
      "0.55\n",
      "0.46\n",
      "0.66\n",
      "0.63\n",
      "0.66\n",
      "0.73\n",
      "0.56\n",
      "0.71\n",
      "0.58\n",
      "0.53\n",
      "0.5\n",
      "0.72\n",
      "0.74\n",
      "0.72\n",
      "0.68\n",
      "0.68\n",
      "0.59\n",
      "0.76\n",
      "0.63\n",
      "0.7\n",
      "0.7\n",
      "0.7\n",
      "0.55\n",
      "0.63\n",
      "0.56\n",
      "0.66\n",
      "0.64\n",
      "0.74\n",
      "0.73\n",
      "0.59\n",
      "0.67\n",
      "0.62\n",
      "0.68\n",
      "0.72\n",
      "0.65\n",
      "0.78\n",
      "0.66\n",
      "0.69\n",
      "0.66\n",
      "0.6\n",
      "0.69\n",
      "0.75\n",
      "0.66\n",
      "0.64\n",
      "0.29\n",
      "0.53\n",
      "0.49\n",
      "0.74\n",
      "0.86\n",
      "0.58\n",
      "0.78\n",
      "0.51\n",
      "0.68\n",
      "0.75\n",
      "0.66\n",
      "0.58\n",
      "0.76\n",
      "0.7\n",
      "0.68\n",
      "0.7\n",
      "0.67\n",
      "0.67\n",
      "0.72\n",
      "0.77\n",
      "0.73\n",
      "0.67\n",
      "0.72\n",
      "0.67\n",
      "0.75\n",
      "0.8\n",
      "0.56\n",
      "0.53\n",
      "0.6\n",
      "0.56\n",
      "0.65\n",
      "0.81\n",
      "0.66\n",
      "0.58\n",
      "0.7\n",
      "0.66\n",
      "0.64\n",
      "0.87\n",
      "0.55\n",
      "0.52\n",
      "0.88\n",
      "0.82\n",
      "0.64\n",
      "0.52\n",
      "0.55\n",
      "0.56\n",
      "0.71\n",
      "0.64\n",
      "0.81\n",
      "0.78\n",
      "0.63\n",
      "0.73\n",
      "0.6\n",
      "0.65\n",
      "0.64\n",
      "0.64\n",
      "0.47\n",
      "0.59\n",
      "0.86\n",
      "0.55\n",
      "0.61\n",
      "0.63\n",
      "0.73\n",
      "0.53\n",
      "0.48\n",
      "0.6\n",
      "0.59\n",
      "0.65\n",
      "0.71\n",
      "0.64\n",
      "0.72\n",
      "0.54\n",
      "0.72\n",
      "0.7\n",
      "0.61\n",
      "0.59\n",
      "0.8\n",
      "0.75\n",
      "0.54\n",
      "0.55\n",
      "0.68\n",
      "0.59\n",
      "0.61\n",
      "0.77\n",
      "0.83\n",
      "0.51\n",
      "0.68\n",
      "0.7\n",
      "0.6\n",
      "0.62\n",
      "0.63\n",
      "0.63\n",
      "0.63\n",
      "0.67\n",
      "0.55\n",
      "0.68\n",
      "0.41\n",
      "0.8\n",
      "0.62\n",
      "0.62\n",
      "0.59\n",
      "0.69\n",
      "0.59\n",
      "0.56\n",
      "0.81\n",
      "0.7\n",
      "0.63\n",
      "0.72\n",
      "0.66\n",
      "0.69\n",
      "0.62\n",
      "0.74\n",
      "0.59\n",
      "0.61\n",
      "0.81\n",
      "0.48\n",
      "0.45\n",
      "0.66\n",
      "0.67\n",
      "0.71\n",
      "0.55\n",
      "0.68\n",
      "0.68\n",
      "0.67\n",
      "0.62\n",
      "0.51\n",
      "0.6\n",
      "0.5\n",
      "0.48\n",
      "0.53\n",
      "0.56\n",
      "0.61\n",
      "0.79\n",
      "0.46\n",
      "0.51\n",
      "0.71\n",
      "0.71\n",
      "0.68\n",
      "0.62\n",
      "0.69\n",
      "0.61\n",
      "0.63\n",
      "0.59\n",
      "0.32\n",
      "0.77\n",
      "0.52\n",
      "0.65\n",
      "0.59\n",
      "0.58\n",
      "0.58\n",
      "0.53\n",
      "0.55\n",
      "0.53\n",
      "0.54\n",
      "0.65\n",
      "0.65\n",
      "0.66\n",
      "0.64\n"
     ]
    }
   ],
   "source": [
    "for x in dff.age:\n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radiomics_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
