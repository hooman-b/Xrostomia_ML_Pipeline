{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Final DataFrame\n",
    "In this notebook, I will present the pipeline that I made to make the dataframe used in the Deep/Machine Learning models.\n",
    "\n",
    "## Introduction\n",
    "This notebook is the source of the python version of the pipeline. This one is more complete, and it contains labelizing and making dummies. So if one does not really want to use this notebook for the whole process they can make the dataset using the python pipeline, then implement the last part of this piepline in the wy that they want.\n",
    "\n",
    "In this Notebook, I will describe the stages that I took to make the two main dataframes of my study.\n",
    "\n",
    "## Make Main DataFrame\n",
    "In this section, I will describe the stages that I took to make the main dataset, that contains 255 patients for 12-month endpoint and 303 patients for 6-month endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "# General packages\n",
    "import os\n",
    "import re\n",
    "import math \n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import scipy.ndimage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Image analysis packages\n",
    "import cv2\n",
    "import pydicom\n",
    "from pydicom.tag import Tag\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "from radiomics import featureextractor\n",
    "from skimage.draw import polygon\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xer_label_maker(diagnosis): # For the endpoints\n",
    "\n",
    "    if diagnosis in ['Heel erg', 'Nogal']:\n",
    "        return 1\n",
    "\n",
    "    elif diagnosis in ['Een beetje', 'Helemaal niet']:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "def xer_label_maker1(diagnosis): # For the baseline\n",
    "\n",
    "    if diagnosis in ['Een beetje', 'Heel erg', 'Nogal']:\n",
    "        return 1\n",
    "\n",
    "    elif diagnosis in ['Helemaal niet']:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def xer_label_maker2(diagnosis): # For the week1\n",
    "\n",
    "    if diagnosis in ['Heel erg', 'Nogal']:\n",
    "        return 2\n",
    "\n",
    "    elif diagnosis in ['Een beetje']:\n",
    "        return 1\n",
    "    \n",
    "    elif diagnosis in ['Helemaal niet']:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def sex_label_maker(diagnosis): \n",
    "\n",
    "    if diagnosis in ['Man']:\n",
    "        return 1\n",
    "    \n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce the links\n",
    "dlc_bsl_path = 'C:/Users/BahrdoH/OneDrive - UMCG/Hooman/Models/Preprocessing/Delta_radiomics/Feature_extraction_factory/Radiomics_features/Rf_bsl_dlc_total.xlsx'\n",
    "dlc_wk3_path = 'C:/Users/BahrdoH/OneDrive - UMCG/Hooman/Models/Preprocessing/Delta_radiomics/Feature_extraction_factory/Radiomics_features/Rf_wk3_dlc_total.xlsx'\n",
    "xer_path = 'C:/Users/BahrdoH/OneDrive - UMCG/Hooman/Models/Preprocessing/Delta_radiomics/Feature_extraction_factory/Radiomics_features/Sanne_dataset/Xerostomia_dataset.xlsx'\n",
    "dose_path  = 'C:/Users/BahrdoH/OneDrive - UMCG/Hooman/Models/Preprocessing/Delta_radiomics/Feature_extraction_factory/Radiomics_features/DLC_RTDOSE1.xlsx'\n",
    "extra_dlc_bsl_path = 'C:/Users/BahrdoH/OneDrive - UMCG/Hooman/Models/Preprocessing/Delta_radiomics/Feature_extraction_factory/Radiomics_features/Extra_Rf_bsl_dlc_total.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make week3 df ()\n",
    "dlc_wk3_df = pd.read_excel(dlc_wk3_path).drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Slice the necessary part of Xerostomia datset\n",
    "xer_df = pd.read_excel(xer_path)\n",
    "xer_df['UMCG'] = xer_df['UMCG'].fillna(0).astype(int)\n",
    "xer_df = xer_df.loc[:,['UMCG', 'GESLACHT', 'LEEFTIJD', 'Modality_adjusted', 'HN35_Xerostomia_BSL',\n",
    "                       'Loctum2', 'HN35_Xerostomia_W01', 'HN35_Xerostomia_M06', 'HN35_Xerostomia_M12',\n",
    "                    'Submandibular_Dmean', 'Parotid_L_Dmean', 'Parotid_R_Dmean']].reset_index().drop(columns=['index'])\n",
    "\n",
    "xer_df = xer_df[xer_df.UMCG.isin(dlc_wk3_df.ID)].reset_index().drop(columns=['index']) # Slice the part that we have in weekly CTs\n",
    "\n",
    "## Read and reshape the dose df\n",
    "dose_df = pd.read_excel(dose_path).drop(columns=['Unnamed: 0'])\n",
    "dose_df = dose_df.loc[:,['ID', 'name', 'mean']]\n",
    "# Use pivot to reshape the DataFrame\n",
    "dose_df = dose_df.pivot(index='ID', columns='name', values='mean')\n",
    "# Reset the index to make 'ID' a regular column\n",
    "dose_df.reset_index(inplace=True)\n",
    "# Rename the columns for clarity\n",
    "dose_df.columns.name = None \n",
    "dose_df['OAR'] = dose_df.idxmin(axis=1)\n",
    "dose_df['OAR'] = dose_df['OAR'].str.replace('DLC_', '')\n",
    "dose_df['Contra_Dmean'] = dose_df.min(axis=1)\n",
    "dose_df = dose_df.drop(columns=['DLC_Parotid_R', 'DLC_Parotid_L'])\n",
    "dose_df = dose_df[dose_df.ID.isin(dlc_wk3_df.ID)].reset_index().drop(columns=['index']) # Slice the part that we have in weekly CTs\n",
    "\n",
    "## Convert the dlc baseline datafram in a comparieble way.\n",
    "dlc_bsl_df = pd.read_excel(dlc_bsl_path)\n",
    "dlc_bsl_df['Unnamed: 0'] = dlc_bsl_df['Unnamed: 0'].fillna(method='ffill')\n",
    "dlc_bsl_df.rename(columns= {'Unnamed: 0':'ID', 'Unnamed: 1': 'OAR'}, inplace=True)\n",
    "dlc_bsl_df.ID = dlc_bsl_df.ID.astype(int)\n",
    "\n",
    "## Concat extra bsl df with the original one.\n",
    "extra_dlc_bsl_df = pd.read_excel(extra_dlc_bsl_path)\n",
    "extra_dlc_bsl_df = extra_dlc_bsl_df.drop(columns=['Unnamed: 0'])\n",
    "dlc_bsl_df = pd.concat([dlc_bsl_df, extra_dlc_bsl_df]).sort_values(by='ID').reset_index().drop(columns=['index'])\n",
    "dlc_bsl_df = dlc_bsl_df[dlc_bsl_df.ID.isin(dlc_wk3_df.ID)].reset_index().drop(columns=['index']) # Slice the part that we have in weekly CTs\n",
    "\n",
    "# Preparing DLC baseline and week3 surface area\n",
    "dlc_wk3_df = dlc_wk3_df.loc[:, ['ID', 'OAR', 'original_shape_SurfaceArea']].rename(columns={'original_shape_SurfaceArea': 'surface_wk3_dlc'}).reset_index().drop(columns=['index'])\n",
    "dlc_bsl_df = dlc_bsl_df.loc[:, ['ID', 'OAR', 'original_shape_SurfaceArea']].rename(columns={'original_shape_SurfaceArea': 'surface_bsl_dlc'}).reset_index().drop(columns=['index'])\n",
    "\n",
    "dlc_bsl_final_df = pd.DataFrame()\n",
    "dlc_wk3_final_df = pd.DataFrame()\n",
    "\n",
    "for counter, raw in dose_df.iterrows():\n",
    "    assistant_bsl_df = dlc_bsl_df[dlc_bsl_df.ID == raw.ID]\n",
    "    assistant_bsl_df = assistant_bsl_df[assistant_bsl_df.OAR.str.contains(raw.OAR)]\n",
    "\n",
    "    assistant_wk3_df = dlc_wk3_df[dlc_wk3_df.ID == raw.ID]\n",
    "    assistant_wk3_df = assistant_wk3_df[assistant_wk3_df.OAR.str.contains(raw.OAR)]\n",
    "    dlc_bsl_final_df = pd.concat([dlc_bsl_final_df,assistant_bsl_df])\n",
    "    dlc_wk3_final_df = pd.concat([dlc_wk3_final_df,assistant_wk3_df])\n",
    "\n",
    "dlc_bsl_final_df = dlc_bsl_final_df.reset_index().drop(columns=['index'])\n",
    "dlc_bsl_final_df = dlc_bsl_final_df.rename(columns={'OAR': 'OAR_bsl_dlc'})\n",
    "dlc_wk3_final_df = dlc_wk3_final_df.reset_index().drop(columns=['index'])\n",
    "dlc_wk3_final_df = dlc_wk3_final_df.rename(columns={'OAR': 'OAR_wk3_dlc'})\n",
    "\n",
    "# Assemble the final dataset\n",
    "final_df = dlc_bsl_final_df.merge(dlc_wk3_final_df, on='ID', how='inner')\n",
    "final_df = final_df.merge(dose_df, on='ID', how='inner')\n",
    "final_df = final_df.merge(xer_df, left_on='ID', right_on='UMCG', how='inner')\n",
    "final_df = final_df.drop(columns=['OAR_bsl_dlc', 'OAR_wk3_dlc', 'UMCG'])\n",
    "\n",
    "# Make the delta_surface column\n",
    "final_df['delta_surf_dlc'] = (final_df.surface_bsl_dlc - final_df.surface_wk3_dlc) / 100 \n",
    "\n",
    "# Rename some of the labels\n",
    "final_df = final_df.rename(columns={'GESLACHT': 'sex', 'LEEFTIJD': 'age',\n",
    "                         'HN35_Xerostomia_BSL': 'xer_bsl', 'HN35_Xerostomia_W01': 'xer_wk1',\n",
    "                         'HN35_Xerostomia_M06': 'xer_06', 'HN35_Xerostomia_M12': 'xer_12'})\n",
    "\n",
    "# Make a copy of xer_bsl column for CITOR model (this one should be divided into three columns)\n",
    "final_df['xer_bsl_citor'] = final_df['xer_bsl'].copy()\n",
    "\n",
    "# convert the labels to 0 and 1\n",
    "final_df.xer_bsl = [xer_label_maker1(diagnosis) for diagnosis in final_df.xer_bsl]\n",
    "final_df.xer_bsl_citor = [xer_label_maker2(diagnosis) for diagnosis in final_df.xer_bsl_citor]\n",
    "final_df.xer_wk1 = [xer_label_maker2(diagnosis) for diagnosis in final_df.xer_wk1]\n",
    "final_df.xer_06 = [xer_label_maker(diagnosis) for diagnosis in final_df.xer_06]\n",
    "final_df.xer_12 = [xer_label_maker(diagnosis) for diagnosis in final_df.xer_12]\n",
    "final_df.sex = [sex_label_maker(diagnosis) for diagnosis in final_df.sex]\n",
    "\n",
    "\n",
    "# Separate xer_wk1 column into 3 columns (Create dummy columns for xer_wk1)\n",
    "dummy_columns = pd.get_dummies(final_df['xer_wk1'])\n",
    "final_df = pd.concat([final_df, dummy_columns], axis=1) # Add it to the main Dataset\n",
    "final_df = final_df.rename(columns={0: 'xer_wk1_not_at_all', 1: 'xer_wk1_little', 2: 'xer_wk1_moderate_to_severe'})\n",
    "\n",
    "# Separate xer_bsl_citor column into 3 columns (Create dummy columns for xer_bsl)\n",
    "dummy_columns = pd.get_dummies(final_df['xer_bsl_citor'])\n",
    "final_df = pd.concat([final_df, dummy_columns], axis=1) # Add it to the main Dataset\n",
    "final_df = final_df.rename(columns={0: 'xer_bsl_not_at_all', 1: 'xer_bsl_little', 2: 'xer_bsl_moderate_to_severe'})\n",
    "\n",
    "# Convert parotid_l and Parotid_r doses into the proper form for CITOR\n",
    "final_df['sqr_parotid_Dmean'] = np.sqrt(final_df.Parotid_L_Dmean) + np.sqrt(final_df.Parotid_R_Dmean)\n",
    "\n",
    "# Make 12 and 6 month datasets\n",
    "six_month_df = final_df[~(final_df.xer_06 == 2)]\n",
    "six_month_df = six_month_df.reset_index().drop(columns=['index'])\n",
    "\n",
    "twelve_month_df = final_df[~(final_df.xer_12 == 2)]\n",
    "twelve_month_df = twelve_month_df.reset_index().drop(columns=['index'])\n",
    "\n",
    "# Add a Split column\n",
    "six_month_df_x = six_month_df.drop(columns=['xer_12'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(six_month_df_x, six_month_df.xer_06, test_size=0.15, random_state=42)\n",
    "\n",
    "six_month_df['Split'] = ['train_val' if idd in list(X_train.ID) else 'test' for idd in six_month_df.ID]\n",
    "\n",
    "twelve_month_df = twelve_month_df.drop(columns=['xer_06'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(twelve_month_df, twelve_month_df.xer_12, test_size=0.15, random_state=42)\n",
    "\n",
    "twelve_month_df['Split'] = ['train_val' if idd in list(X_train.ID) else 'test' for idd in twelve_month_df.ID]\n",
    "\n",
    "# Save the dataframes\n",
    "twelve_month_df.to_excel('delta_rf_df_12.xlsx')\n",
    "six_month_df.to_excel('delta_rf_6month.xlsx')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
