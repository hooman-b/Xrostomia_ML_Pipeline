{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Final DataFrame\n",
    "In this notebook, I will present the pipeline that I made to make the dataframe used in the Deep/Machine Learning models.\n",
    "\n",
    "## Introduction\n",
    "This notebook is the source of the python version of the pipeline. This one is more complete, and it contains labelizing and making dummies. So if one does not really want to use this notebook for the whole process they can make the dataset using the python pipeline, then implement the last part of this piepline in the wy that they want.\n",
    "\n",
    "In this Notebook, I will describe the stages that I took to make the two main dataframes of my study.\n",
    "\n",
    "## Make Main DataFrame\n",
    "In this section, I will describe the stages that I took to make the main dataset, that contains 255 patients for 12-month endpoint and 303 patients for 6-month endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "# General packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xer_label_maker(diagnosis): # For the endpoints\n",
    "\n",
    "    if diagnosis in ['Heel erg', 'Nogal']:\n",
    "        return 1\n",
    "\n",
    "    elif diagnosis in ['Een beetje', 'Helemaal niet']:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "def xer_label_maker1(diagnosis): # For the baseline\n",
    "\n",
    "    if diagnosis in ['Een beetje', 'Heel erg', 'Nogal']:\n",
    "        return 1\n",
    "\n",
    "    elif diagnosis in ['Helemaal niet']:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def xer_label_maker2(diagnosis): # For the week1\n",
    "\n",
    "    if diagnosis in ['Heel erg', 'Nogal']:\n",
    "        return 2\n",
    "\n",
    "    elif diagnosis in ['Een beetje']:\n",
    "        return 1\n",
    "    \n",
    "    elif diagnosis in ['Helemaal niet']:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def sex_label_maker(diagnosis): \n",
    "\n",
    "    if diagnosis in ['Man']:\n",
    "        return 1\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def xer_label_maker_sanne1(diagnosis): # For the baseline\n",
    "\n",
    "    if diagnosis in [2.0, 3.0, 4.0]:\n",
    "        return 1\n",
    "\n",
    "    elif diagnosis in [1.0]:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def xer_label_maker_sanne2(diagnosis): # For the week1\n",
    "\n",
    "    if diagnosis in [3.0, 4.0]:\n",
    "        return 1\n",
    "\n",
    "    elif diagnosis in [1.0, 2.0]:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce the links\n",
    "dlc_bsl_path = 'C:/Users/BahrdoH/OneDrive - UMCG/Hooman/Models/Preprocessing/Delta_radiomics/Feature_extraction_factory/Radiomics_features/Rf_bsl_dlc_total.xlsx'\n",
    "dlc_wk3_path = 'C:/Users/BahrdoH/OneDrive - UMCG/Hooman/Models/Preprocessing/Delta_radiomics/Feature_extraction_factory/Radiomics_features/Rf_wk3_dlc_total.xlsx'\n",
    "xer_path = 'C:/Users/BahrdoH/OneDrive - UMCG/Hooman/Models/Preprocessing/Delta_radiomics/Feature_extraction_factory/Radiomics_features/Sanne_dataset/Xerostomia_dataset.xlsx'\n",
    "dose_path  = 'C:/Users/BahrdoH/OneDrive - UMCG/Hooman/Models/Preprocessing/Delta_radiomics/Feature_extraction_factory/Radiomics_features/DLC_RTDOSE1.xlsx'\n",
    "extra_dlc_bsl_path = 'C:/Users/BahrdoH/OneDrive - UMCG/Hooman/Models/Preprocessing/Delta_radiomics/Feature_extraction_factory/Radiomics_features/Extra_Rf_bsl_dlc_total.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make week3 df ()\n",
    "dlc_wk3_df = pd.read_excel(dlc_wk3_path).drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Slice the necessary part of Xerostomia datset\n",
    "xer_df = pd.read_excel(xer_path)\n",
    "xer_df['UMCG'] = xer_df['UMCG'].fillna(0).astype(int)\n",
    "xer_df = xer_df.loc[:,['UMCG', 'GESLACHT', 'LEEFTIJD', 'Modality_adjusted', 'HN35_Xerostomia_BSL',\n",
    "                       'Loctum2', 'HN35_Xerostomia_W01', 'HN35_Xerostomia_M06', 'HN35_Xerostomia_M12',\n",
    "                    'Submandibular_Dmean', 'Parotid_L_Dmean', 'Parotid_R_Dmean']].reset_index().drop(columns=['index'])\n",
    "\n",
    "xer_df = xer_df[xer_df.UMCG.isin(dlc_wk3_df.ID)].reset_index().drop(columns=['index']) # Slice the part that we have in weekly CTs\n",
    "\n",
    "## Read and reshape the dose df\n",
    "dose_df = pd.read_excel(dose_path).drop(columns=['Unnamed: 0'])\n",
    "dose_df = dose_df.loc[:,['ID', 'name', 'mean']]\n",
    "# Use pivot to reshape the DataFrame\n",
    "dose_df = dose_df.pivot(index='ID', columns='name', values='mean')\n",
    "# Reset the index to make 'ID' a regular column\n",
    "dose_df.reset_index(inplace=True)\n",
    "# Rename the columns for clarity\n",
    "dose_df.columns.name = None \n",
    "dose_df['OAR'] = dose_df.idxmin(axis=1)\n",
    "dose_df['OAR'] = dose_df['OAR'].str.replace('DLC_', '')\n",
    "dose_df['Contra_Dmean'] = dose_df.min(axis=1)\n",
    "dose_df = dose_df.drop(columns=['DLC_Parotid_R', 'DLC_Parotid_L'])\n",
    "dose_df = dose_df[dose_df.ID.isin(dlc_wk3_df.ID)].reset_index().drop(columns=['index']) # Slice the part that we have in weekly CTs\n",
    "\n",
    "## Convert the dlc baseline datafram in a comparieble way.\n",
    "dlc_bsl_df = pd.read_excel(dlc_bsl_path)\n",
    "dlc_bsl_df['Unnamed: 0'] = dlc_bsl_df['Unnamed: 0'].fillna(method='ffill')\n",
    "dlc_bsl_df.rename(columns= {'Unnamed: 0':'ID', 'Unnamed: 1': 'OAR'}, inplace=True)\n",
    "dlc_bsl_df.ID = dlc_bsl_df.ID.astype(int)\n",
    "\n",
    "## Concat extra bsl df with the original one.\n",
    "extra_dlc_bsl_df = pd.read_excel(extra_dlc_bsl_path)\n",
    "extra_dlc_bsl_df = extra_dlc_bsl_df.drop(columns=['Unnamed: 0'])\n",
    "dlc_bsl_df = pd.concat([dlc_bsl_df, extra_dlc_bsl_df]).sort_values(by='ID').reset_index().drop(columns=['index'])\n",
    "dlc_bsl_df = dlc_bsl_df[dlc_bsl_df.ID.isin(dlc_wk3_df.ID)].reset_index().drop(columns=['index']) # Slice the part that we have in weekly CTs\n",
    "\n",
    "# Preparing DLC baseline and week3 surface area\n",
    "dlc_wk3_df = dlc_wk3_df.loc[:, ['ID', 'OAR', 'original_shape_SurfaceArea']].rename(columns={'original_shape_SurfaceArea': 'surface_wk3_dlc'}).reset_index().drop(columns=['index'])\n",
    "dlc_bsl_df = dlc_bsl_df.loc[:, ['ID', 'OAR', 'original_shape_SurfaceArea']].rename(columns={'original_shape_SurfaceArea': 'surface_bsl_dlc'}).reset_index().drop(columns=['index'])\n",
    "\n",
    "dlc_bsl_final_df = pd.DataFrame()\n",
    "dlc_wk3_final_df = pd.DataFrame()\n",
    "\n",
    "for counter, raw in dose_df.iterrows():\n",
    "    assistant_bsl_df = dlc_bsl_df[dlc_bsl_df.ID == raw.ID]\n",
    "    assistant_bsl_df = assistant_bsl_df[assistant_bsl_df.OAR.str.contains(raw.OAR)]\n",
    "\n",
    "    assistant_wk3_df = dlc_wk3_df[dlc_wk3_df.ID == raw.ID]\n",
    "    assistant_wk3_df = assistant_wk3_df[assistant_wk3_df.OAR.str.contains(raw.OAR)]\n",
    "    dlc_bsl_final_df = pd.concat([dlc_bsl_final_df,assistant_bsl_df])\n",
    "    dlc_wk3_final_df = pd.concat([dlc_wk3_final_df,assistant_wk3_df])\n",
    "\n",
    "dlc_bsl_final_df = dlc_bsl_final_df.reset_index().drop(columns=['index'])\n",
    "dlc_bsl_final_df = dlc_bsl_final_df.rename(columns={'OAR': 'OAR_bsl_dlc'})\n",
    "dlc_wk3_final_df = dlc_wk3_final_df.reset_index().drop(columns=['index'])\n",
    "dlc_wk3_final_df = dlc_wk3_final_df.rename(columns={'OAR': 'OAR_wk3_dlc'})\n",
    "\n",
    "# Assemble the final dataset\n",
    "final_df = dlc_bsl_final_df.merge(dlc_wk3_final_df, on='ID', how='inner')\n",
    "final_df = final_df.merge(dose_df, on='ID', how='inner')\n",
    "final_df = final_df.merge(xer_df, left_on='ID', right_on='UMCG', how='inner')\n",
    "final_df = final_df.drop(columns=['OAR_bsl_dlc', 'OAR_wk3_dlc', 'UMCG'])\n",
    "\n",
    "# Make the delta_surface column\n",
    "final_df['delta_surf_dlc'] = (final_df.surface_bsl_dlc - final_df.surface_wk3_dlc) / 100 \n",
    "\n",
    "# Rename some of the labels\n",
    "final_df = final_df.rename(columns={'GESLACHT': 'sex', 'LEEFTIJD': 'age',\n",
    "                         'HN35_Xerostomia_BSL': 'xer_bsl', 'HN35_Xerostomia_W01': 'xer_wk1',\n",
    "                         'HN35_Xerostomia_M06': 'xer_06', 'HN35_Xerostomia_M12': 'xer_12'})\n",
    "\n",
    "# Make a copy of xer_bsl column for CITOR model (this one should be divided into three columns)\n",
    "final_df['xer_bsl_citor'] = final_df['xer_bsl'].copy()\n",
    "\n",
    "# convert the labels to 0 and 1\n",
    "final_df.xer_bsl = [xer_label_maker1(diagnosis) for diagnosis in final_df.xer_bsl]\n",
    "final_df.xer_bsl_citor = [xer_label_maker2(diagnosis) for diagnosis in final_df.xer_bsl_citor]\n",
    "final_df.xer_wk1 = [xer_label_maker2(diagnosis) for diagnosis in final_df.xer_wk1]\n",
    "final_df.xer_06 = [xer_label_maker(diagnosis) for diagnosis in final_df.xer_06]\n",
    "final_df.xer_12 = [xer_label_maker(diagnosis) for diagnosis in final_df.xer_12]\n",
    "final_df.sex = [sex_label_maker(diagnosis) for diagnosis in final_df.sex]\n",
    "\n",
    "\n",
    "# Separate xer_wk1 column into 3 columns (Create dummy columns for xer_wk1)\n",
    "dummy_columns = pd.get_dummies(final_df['xer_wk1'])\n",
    "final_df = pd.concat([final_df, dummy_columns], axis=1) # Add it to the main Dataset\n",
    "final_df = final_df.rename(columns={0: 'xer_wk1_not_at_all', 1: 'xer_wk1_little', 2: 'xer_wk1_moderate_to_severe'})\n",
    "\n",
    "# Separate xer_bsl_citor column into 3 columns (Create dummy columns for xer_bsl)\n",
    "dummy_columns = pd.get_dummies(final_df['xer_bsl_citor'])\n",
    "final_df = pd.concat([final_df, dummy_columns], axis=1) # Add it to the main Dataset\n",
    "final_df = final_df.rename(columns={0: 'xer_bsl_not_at_all', 1: 'xer_bsl_little', 2: 'xer_bsl_moderate_to_severe'})\n",
    "\n",
    "# Convert parotid_l and Parotid_r doses into the proper form for CITOR\n",
    "final_df['sqr_parotid_Dmean'] = np.sqrt(final_df.Parotid_L_Dmean) + np.sqrt(final_df.Parotid_R_Dmean)\n",
    "\n",
    "# Make 12 and 6 month datasets\n",
    "six_month_df = final_df[~(final_df.xer_06 == 2)]\n",
    "six_month_df = six_month_df.reset_index().drop(columns=['index'])\n",
    "\n",
    "twelve_month_df = final_df[~(final_df.xer_12 == 2)]\n",
    "twelve_month_df = twelve_month_df.reset_index().drop(columns=['index'])\n",
    "\n",
    "# Add a Split column\n",
    "six_month_df_x = six_month_df.drop(columns=['xer_12'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(six_month_df_x, six_month_df.xer_06, test_size=0.15, random_state=42)\n",
    "\n",
    "six_month_df['Split'] = ['train_val' if idd in list(X_train.ID) else 'test' for idd in six_month_df.ID]\n",
    "\n",
    "twelve_month_df = twelve_month_df.drop(columns=['xer_06'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(twelve_month_df, twelve_month_df.xer_12, test_size=0.15, random_state=42)\n",
    "\n",
    "twelve_month_df['Split'] = ['train_val' if idd in list(X_train.ID) else 'test' for idd in twelve_month_df.ID]\n",
    "\n",
    "# Save the dataframes\n",
    "twelve_month_df.to_excel('delta_rf_df_12.xlsx')\n",
    "six_month_df.to_excel('delta_rf_6month.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the dataset of Delta-radiomics article (2019)\n",
    "This dataset belong to the article of Delta-radiomics model (2019) that contains 68 patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc_bsl_path = 'C:/Users/BahrdoH/OneDrive - UMCG/Hooman/Models/Preprocessing/Delta_radiomics/Feature_extraction_factory/Radiomics_features/Sanne_dataset/Rf_bsl_dlc_sanne.xlsx'\n",
    "dlc_wk3_path = 'C:/Users/BahrdoH/OneDrive - UMCG/Hooman/Models/Preprocessing/Delta_radiomics/Feature_extraction_factory/Radiomics_features/Sanne_dataset/Rf_wk3_dlc_sanne1.xlsx'\n",
    "mc_bsl_path = 'C:/Users/BahrdoH/OneDrive - UMCG/Hooman/Models/Preprocessing/Delta_radiomics/Feature_extraction_factory/Radiomics_features/Sanne_dataset/Rf_bsl_mc_sanne.xlsx'\n",
    "mc_wk3_path = 'C:/Users/BahrdoH/OneDrive - UMCG/Hooman/Models/Preprocessing/Delta_radiomics/Feature_extraction_factory/Radiomics_features/Sanne_dataset/Rf_wk3_mc_sanne.xlsx'\n",
    "\n",
    "xer_path = 'C:/Users/BahrdoH/OneDrive - UMCG/Hooman/Models/Preprocessing/Delta_radiomics/Feature_extraction_factory/Radiomics_features/Sanne_dataset/Xerostomia_dataset.xlsx'\n",
    "dlc_dose_path  = '//zkh/appdata/RTDicom/Projectline_HNC_modelling/OPC_data/ART Hooman/Hooman_project_data/Sanne_dataset/DLC_baseline_RTSTRUCT/DLC_RTDOSE_SANNE.xlsx'\n",
    "mc_dose_path  = '//zkh/appdata/RTDicom/Projectline_HNC_modelling/OPC_data/ART Hooman/Hooman_project_data/Sanne_dataset/DLC_baseline_RTSTRUCT/MC_RTDOSE_SANNE.xlsx'\n",
    "label_path = 'C:/Users/BahrdoH/OneDrive - UMCG/Hooman/Models/Preprocessing/Delta_radiomics/Feature_extraction_factory/Radiomics_features/Sanne_dataset/endpoints_xer2.xls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataframe.\n",
    "mc_wk3_df = pd.read_excel(mc_wk3_path).drop(columns=['Unnamed: 0'])\n",
    "mc_bsl_df = pd.read_excel(mc_bsl_path).drop(columns=['Unnamed: 0'])\n",
    "dlc_wk3_df = pd.read_excel(dlc_wk3_path).drop(columns=['Unnamed: 0'])\n",
    "dlc_bsl_df = pd.read_excel(dlc_bsl_path).drop(columns=['Unnamed: 0'])\n",
    "\n",
    "\n",
    "# Preparing DLC baseline and week3 surface area\n",
    "dlc_wk3_df = dlc_wk3_df.loc[:, ['ID', 'OAR', 'original_shape_SurfaceArea']].rename(columns={'original_shape_SurfaceArea': 'surface_wk3_dlc'}).reset_index().drop(columns=['index'])\n",
    "dlc_bsl_df = dlc_bsl_df.loc[:, ['ID', 'OAR', 'original_shape_SurfaceArea']].rename(columns={'original_shape_SurfaceArea': 'surface_bsl_dlc'}).reset_index().drop(columns=['index'])\n",
    "mc_wk3_df = mc_wk3_df.loc[:, ['ID', 'OAR', 'original_shape_SurfaceArea']].rename(columns={'original_shape_SurfaceArea': 'surface_wk3_mc'}).reset_index().drop(columns=['index'])\n",
    "mc_bsl_df = mc_bsl_df.loc[:, ['ID', 'OAR', 'original_shape_SurfaceArea']].rename(columns={'original_shape_SurfaceArea': 'surface_bsl_mc'}).reset_index().drop(columns=['index'])\n",
    "\n",
    "# Slice the necessary part of Xerostomia datset\n",
    "label_df = pd.read_excel(label_path)\n",
    "label_df = label_df.loc[:,['umcgnum', 'XER_w', 'Pati_baseline', 'Pati_6m', 'Pati_12m',]].reset_index().drop(columns=['index'])\n",
    "label_df = label_df[label_df.umcgnum.isin(dlc_wk3_df.ID)].reset_index().drop(columns=['index']) # Slice the part that we have in weekly CTs\n",
    "\n",
    "## Read and reshape the dose df\n",
    "dlc_dose_df = pd.read_excel(dlc_dose_path).drop(columns=['Unnamed: 0'])\n",
    "dlc_dose_df = dlc_dose_df.loc[:,['ID', 'name', 'mean']]\n",
    "# Use pivot to reshape the DataFrame\n",
    "dlc_dose_df = dlc_dose_df.pivot(index='ID', columns='name', values='mean')\n",
    "# Reset the index to make 'ID' a regular column\n",
    "dlc_dose_df.reset_index(inplace=True)\n",
    "# Rename the columns for clarity\n",
    "dlc_dose_df.columns.name = None \n",
    "dlc_dose_df['OAR'] = dlc_dose_df.idxmin(axis=1)\n",
    "dlc_dose_df['OAR'] = dlc_dose_df['OAR'].str.replace('DLC_', '')\n",
    "dlc_dose_df['Contra_Dmean'] = dlc_dose_df.min(axis=1)\n",
    "dlc_dose_df = dlc_dose_df.drop(columns=['DLC_Parotid_R', 'DLC_Parotid_L'])\n",
    "dlc_dose_df = dlc_dose_df[dlc_dose_df.ID.isin(dlc_wk3_df.ID)].reset_index().drop(columns=['index']) # Slice the part that we have in weekly CTs\n",
    "\n",
    "## Read and reshape the dose df (Manual contours) (RECHECK THIS IF YOU HAVE WRONG ANSWERS) ##################\n",
    "mc_dose_df = pd.read_excel(mc_dose_path).drop(columns=['Unnamed: 0'])\n",
    "mc_dose_df = mc_dose_df.loc[:,['ID', 'name', 'mean']]\n",
    "mc_dose_df = mc_dose_df[mc_dose_df.name.str.contains('TA')]\n",
    "# Use pivot to reshape the DataFrame\n",
    "mc_dose_df = mc_dose_df.pivot(index='ID', columns='name', values='mean')\n",
    "# Reset the index to make 'ID' a regular column\n",
    "mc_dose_df.reset_index(inplace=True)\n",
    "# Rename the columns for clarity\n",
    "mc_dose_df.columns.name = None \n",
    "mc_dose_df['OAR'] = mc_dose_df.idxmin(axis=1)\n",
    "mc_dose_df['OAR'] = mc_dose_df['OAR'].str.replace('DLC_', '')\n",
    "mc_dose_df['Contra_Dmean'] = mc_dose_df.min(axis=1)\n",
    "\n",
    "# mc_dose_df = mc_dose_df.drop(columns=['Parotid_L', 'Parotid_L_TA', 'Parotid_R', 'Parotid_R_TA', 'parotis_li', 'parotis_re'])\n",
    "mc_dose_df = mc_dose_df.drop(columns=['Parotid_L_TA', 'Parotid_R_TA'])\n",
    "mc_dose_df = mc_dose_df[mc_dose_df.ID.isin(dlc_wk3_df.ID)].reset_index().drop(columns=['index'])\n",
    "mc_dose_df['OAR'] = mc_dose_df['OAR'].replace('parotis_re', 'Parotid_R')\n",
    "mc_dose_df['OAR'] = mc_dose_df['OAR'].replace('parotis_li', 'Parotid_L')\n",
    "# mc_dose_df['ID'] = mc_dose_df['ID'].replace(3925846, 3952846)\n",
    "\n",
    "\n",
    "dlc_bsl_final_df = pd.DataFrame()\n",
    "dlc_wk3_final_df = pd.DataFrame()\n",
    "mc_bsl_final_df = pd.DataFrame()\n",
    "mc_wk3_final_df = pd.DataFrame()\n",
    "\n",
    "for counter, raw in dlc_dose_df.iterrows():\n",
    "    assistant_bsl_df = dlc_bsl_df[dlc_bsl_df.ID == raw.ID]\n",
    "    \n",
    "    assistant_bsl_df = assistant_bsl_df[assistant_bsl_df.OAR.str.contains(raw.OAR)]\n",
    "    assistant_wk3_df = dlc_wk3_df[dlc_wk3_df.ID == raw.ID]\n",
    "    assistant_wk3_df = assistant_wk3_df[assistant_wk3_df.OAR.str.contains(raw.OAR)]\n",
    "    dlc_bsl_final_df = pd.concat([dlc_bsl_final_df,assistant_bsl_df])\n",
    "    dlc_wk3_final_df = pd.concat([dlc_wk3_final_df,assistant_wk3_df])\n",
    "\n",
    "dlc_bsl_final_df = dlc_bsl_final_df.reset_index().drop(columns=['index'])\n",
    "dlc_bsl_final_df = dlc_bsl_final_df.rename(columns={'OAR': 'OAR_bsl_dlc'})\n",
    "dlc_wk3_final_df = dlc_wk3_final_df.reset_index().drop(columns=['index'])\n",
    "dlc_wk3_final_df = dlc_wk3_final_df.rename(columns={'OAR': 'OAR_wk3_dlc'})\n",
    "\n",
    "mc_bsl_final_rows = []\n",
    "mc_wk3_final_rows = []\n",
    "\n",
    "for counter, raw in mc_dose_df.iterrows():\n",
    "    assistant_bsl_df = mc_bsl_df[(mc_bsl_df.ID == raw.ID) & (mc_bsl_df.OAR.str.contains(raw.OAR))]\n",
    "    assistant_wk3_df = mc_wk3_df[(mc_wk3_df.ID == raw.ID) & (mc_wk3_df.OAR.str.contains(raw.OAR))]\n",
    "\n",
    "    if assistant_wk3_df.shape[0] == 0:\n",
    "        assistant_wk3_df = mc_wk3_df[(mc_wk3_df.ID == raw.ID) & (mc_wk3_df.OAR.str.contains(raw.OAR.replace('_TA', '')))]\n",
    "    if assistant_bsl_df.shape[0] == 0:\n",
    "        assistant_bsl_df = mc_bsl_df[(mc_bsl_df.ID == raw.ID) & (mc_bsl_df.OAR.str.contains(raw.OAR.replace('_TA', '')))]\n",
    "\n",
    "    if raw.ID ==4107088:\n",
    "        assistant_wk3_df = mc_wk3_df[(mc_wk3_df.ID == 4107088) & (mc_wk3_df.OAR.str.contains('parotis_li'))]\n",
    "\n",
    "    if assistant_bsl_df.shape[0] > 1:\n",
    "        for _, row in assistant_bsl_df.iterrows():\n",
    "            if 'ta' in row.OAR.lower():\n",
    "                mc_bsl_final_rows.append(row)\n",
    "    else:\n",
    "        for _, row in assistant_bsl_df.iterrows():\n",
    "            mc_bsl_final_rows.append(row)\n",
    "\n",
    "    if assistant_wk3_df.shape[0] > 1:\n",
    "        for _, row in assistant_wk3_df.iterrows():\n",
    "\n",
    "            if 'ta' in row.OAR.lower():\n",
    "                mc_wk3_final_rows.append(row)\n",
    "    else:\n",
    "        for _, row in assistant_wk3_df.iterrows():\n",
    "            \n",
    "            mc_wk3_final_rows.append(row)\n",
    "\n",
    "mc_bsl_final_df = pd.DataFrame(mc_bsl_final_rows)\n",
    "mc_wk3_final_df = pd.DataFrame(mc_wk3_final_rows)\n",
    "\n",
    "mc_bsl_final_df.reset_index(drop=True, inplace=True)\n",
    "mc_bsl_final_df.rename(columns={'OAR': 'OAR_bsl_mc'}, inplace=True)\n",
    "mc_wk3_final_df.reset_index(drop=True, inplace=True)\n",
    "mc_wk3_final_df.rename(columns={'OAR': 'OAR_wk3_mc'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Assemble the final dataset\n",
    "final_df = dlc_bsl_final_df.merge(dlc_wk3_final_df, on='ID', how='inner')\n",
    "# print(final_df.shape)\n",
    "final_df = final_df.merge(label_df, left_on='ID', right_on='umcgnum', how='inner')\n",
    "print(final_df.shape)\n",
    "final_df = final_df.merge(mc_bsl_final_df, on='ID', how='inner')\n",
    "# print(final_df.shape)\n",
    "final_df = final_df.merge(mc_wk3_final_df, on='ID', how='inner')\n",
    "# print(final_df.shape)\n",
    "final_df = final_df.merge(dlc_dose_df, on='ID', how='inner')\n",
    "# print(final_df.shape)\n",
    "final_df = final_df.merge(mc_dose_df, on='ID', how='inner')\n",
    "# print(final_df.shape)\n",
    "\n",
    "# print(final_df.shape)\n",
    "final_df = final_df.drop(columns=['OAR_bsl_dlc', 'OAR_wk3_dlc', 'umcgnum', 'OAR_wk3_mc', 'OAR_bsl_mc'])\n",
    "\n",
    "\n",
    "# Make the delta_surface column\n",
    "final_df['delta_surf_dlc'] = (final_df.surface_wk3_dlc - final_df.surface_bsl_dlc) / 100 #/ 100. \n",
    "final_df['delta_surf_mc'] = (final_df.surface_wk3_mc - final_df.surface_bsl_mc) / 100 #/1000. #normalizing_feature\n",
    "final_df['delta_surf_mcdlc'] = (final_df.surface_wk3_dlc - final_df.surface_bsl_mc) / 100\n",
    "\n",
    "# Rename some of the labels\n",
    "final_df = final_df.rename(columns={'Pati_baseline': 'xer_bsl', 'XER_w': 'xer_wk1',\n",
    "                                    'Pati_6m': 'xer_06', 'Pati_12m': 'xer_12',\n",
    "                                    'OAR_x': 'OAR_dlc', 'OAR_y': 'OAR_mc',\n",
    "                                    'Contra_Dmean_x': 'Contra_Dmean_dlc',\n",
    "                                    'Contra_Dmean_y': 'Contra_Dmean_mc'})\n",
    "\n",
    "\n",
    "# convert the labels to 0 and 1\n",
    "final_df.xer_bsl = [xer_label_maker_sanne1(diagnosis) for diagnosis in final_df.xer_bsl]\n",
    "final_df.xer_wk1 = [xer_label_maker_sanne1(diagnosis) for diagnosis in final_df.xer_wk1]\n",
    "final_df.xer_06 = [xer_label_maker_sanne2(diagnosis) for diagnosis in final_df.xer_06]\n",
    "final_df.xer_12 = [xer_label_maker_sanne2(diagnosis) for diagnosis in final_df.xer_12]\n",
    "\n",
    "# Make 12 and 6 month datasets\n",
    "six_month_df = final_df[~(final_df.xer_06 == 2)]\n",
    "six_month_df = six_month_df.reset_index().drop(columns=['index'])\n",
    "\n",
    "twelve_month_df = final_df[~(final_df.xer_12 == 2)]\n",
    "twelve_month_df = twelve_month_df.reset_index().drop(columns=['index'])\n",
    "\n",
    "# Sanne_6month_df1 is the best one\n",
    "six_month_df.to_excel('Sanne_6month.xlsx')\n",
    "twelve_month_df.to_excel('Sanne_12month.xlsx')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
